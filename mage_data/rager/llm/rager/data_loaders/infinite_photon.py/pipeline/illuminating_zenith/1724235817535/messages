{"result_id": "202c376b19ab4c05921352671d11008e", "data_type": null, "error": {"code": "from typing import Dict, List, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch, exceptions\n\nindex_name = \"documents_20240821_5016\"\n\n@data_loader\ndef search(*args, **kwargs) -> List[Dict]:\n    \"\"\"\n    query_embedding: Union[List[int], np.ndarray]\n    \"\"\"\n    \n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    index_name = kwargs.get('index_name', 'documents_20240821_5016')\n    source = kwargs.get('source', \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\")\n    top_k = kwargs.get('top_k', 5)\n    chunk_column = kwargs.get('chunk_column', 'content')\n\n    query_embedding = None\n    if len(args):\n        query_embedding = args[0]\n    if not query_embedding:\n        query_embedding = SAMPLE__EMBEDDINGS[0]\n\n    if isinstance(query_embedding, np.ndarray):\n        query_embedding = query_embedding.tolist()\n\n    script_query = {\n        \"script_score\": {\n            \"query\": {\"match_all\": {}},\n            \"script\": {\n                \"source\": source,\n                \"params\": {\"query_vector\": query_embedding},\n            }\n        }\n    }\n\n    print(\"Sending script query:\", script_query)\n\n    es_client = Elasticsearch(connection_string)\n    \n    try:\n        response = es_client.search(\n            index=index_name,\n            body={\n                \"size\": top_k,\n                \"query\": script_query,\n                \"_source\": [chunk_column],\n            },\n        )\n\n        print(\"Raw response from Elasticsearch:\", response)\n\n        return [hit['_source'][chunk_column] for hit in response['hits']['hits']]\n    \n    except exceptions.BadRequestError as e:\n        print(f\"BadRequestError: {e.info}\")\n        return []\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return []", "code_context": ["    if not query_embedding:", "        query_embedding = SAMPLE__EMBEDDINGS[0]", "", "    if isinstance(query_embedding, np.ndarray):", "        query_embedding = query_embedding.tolist()"], "code_context_formatted": ["\u001b[35m  23:     if not query_embedding:\u001b[0m", "\u001b[35m  24:         query_embedding = SAMPLE__EMBEDDINGS[0]\u001b[0m", "\u001b[91m  25: \u001b[0m", "\u001b[35m  26:     if isinstance(query_embedding, np.ndarray):\u001b[0m", "\u001b[35m  27:         query_embedding = query_embedding.tolist()\u001b[0m"], "error": "name 'SAMPLE__EMBEDDINGS' is not defined", "errors": null, "exception": "NameError: name 'SAMPLE__EMBEDDINGS' is not defined", "line_number": 25, "message": "name 'SAMPLE__EMBEDDINGS' is not defined", "message_formatted": "name 'SAMPLE__EMBEDDINGS' is not defined", "stacktrace": ["Traceback (most recent call last):\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\", line 281, in execute_code_async\n    local_variables = await __modify_and_execute(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\", line 135, in __modify_and_execute\n    raise error\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\", line 117, in __modify_and_execute\n    res = await res\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/environments/setup_helpers.py\", line 48, in execute\n    await block.execute(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1711, in execute\n    await loop.run_in_executor(\n", "  File \"/usr/local/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1688, in execute_sync\n    return __execute()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1665, in __execute\n    raise err\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1567, in __execute\n    output = self.execute_block(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1912, in execute_block\n    outputs = self._execute_block(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 2075, in _execute_block\n    outputs = self.execute_block_function(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 2186, in execute_block_function\n    output = block_function_updated(*input_vars, **runtime_variables)\n", "  File \"<string>\", line 25, in search\n", "NameError: name 'SAMPLE__EMBEDDINGS' is not defined\n"], "stacktrace_formatted": ["\u001b[91mTraceback (most recent call last):\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\"\u001b[0m, \u001b[36mline 281\u001b[0m, \u001b[35min execute_code_async\n    local_variables = await __modify_and_execute(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\"\u001b[0m, \u001b[36mline 135\u001b[0m, \u001b[35min __modify_and_execute\n    raise error\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\"\u001b[0m, \u001b[36mline 117\u001b[0m, \u001b[35min __modify_and_execute\n    res = await res\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/environments/setup_helpers.py\"\u001b[0m, \u001b[36mline 48\u001b[0m, \u001b[35min execute\n    await block.execute(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1711\u001b[0m, \u001b[35min execute\n    await loop.run_in_executor(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/concurrent/futures/thread.py\"\u001b[0m, \u001b[36mline 58\u001b[0m, \u001b[35min run\n    result = self.fn(*self.args, **self.kwargs)\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1688\u001b[0m, \u001b[35min execute_sync\n    return __execute()\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1665\u001b[0m, \u001b[35min __execute\n    raise err\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1567\u001b[0m, \u001b[35min __execute\n    output = self.execute_block(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1912\u001b[0m, \u001b[35min execute_block\n    outputs = self._execute_block(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 2075\u001b[0m, \u001b[35min _execute_block\n    outputs = self.execute_block_function(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 2186\u001b[0m, \u001b[35min execute_block_function\n    output = block_function_updated(*input_vars, **runtime_variables)\n\u001b[0m", "\u001b[34m  File \"<string>\"\u001b[0m, \u001b[36mline 25\u001b[0m, \u001b[35min search\n\u001b[0m", "\u001b[90mNameError: name 'SAMPLE__EMBEDDINGS' is not defined\n\u001b[0m", "\u001b[91mname 'SAMPLE__EMBEDDINGS' is not defined\u001b[0m"], "type": "NameError"}, "metadata": null, "output": null, "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "infinite_photon", "message": "from typing import Dict, List, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch, exceptions\n\nindex_name = \"documents_20240821_5016\"\n\n@data_loader\ndef search(*args, **kwargs) -> List[Dict]:\n    \"\"\"\n    query_embedding: Union[List[int], np.ndarray]\n    \"\"\"\n    \n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    index_name = kwargs.get('index_name', 'documents_20240821_5016')\n    source = kwargs.get('source', \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\")\n    top_k = kwargs.get('top_k', 5)\n    chunk_column = kwargs.get('chunk_column', 'content')\n\n    query_embedding = None\n    if len(args):\n        query_embedding = args[0]\n    if not query_embedding:\n        query_embedding = SAMPLE__EMBEDDINGS[0]\n\n    if isinstance(query_embedding, np.ndarray):\n        query_embedding = query_embedding.tolist()\n\n    script_query = {\n        \"script_score\": {\n            \"query\": {\"match_all\": {}},\n            \"script\": {\n                \"source\": source,\n                \"params\": {\"query_vector\": query_embedding},\n            }\n        }\n    }\n\n    print(\"Sending script query:\", script_query)\n\n    es_client = Elasticsearch(connection_string)\n    \n    try:\n        response = es_client.search(\n            index=index_name,\n            body={\n                \"size\": top_k,\n                \"query\": script_query,\n                \"_source\": [chunk_column],\n            },\n        )\n\n        print(\"Raw response from Elasticsearch:\", response)\n\n        return [hit['_source'][chunk_column] for hit in response['hits']['hits']]\n    \n    except exceptions.BadRequestError as e:\n        print(f\"BadRequestError: {e.info}\")\n        return []\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return []", "message_request_uuid": "1724235817535", "message_uuid": "1cc8590d36064f7a8e0fe56a71d84def", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_loaders/infinite_photon.py", "uuid": "1724235817535"}, "pid": "1cc8590d36064f7a8e0fe56a71d84def", "pid_spawn": null, "source": "infinite_photon", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "infinite_photon"}, "status": "error", "type": "status", "uuid": "infinite_photon", "timestamp": 1724235817524, "output_text": null}
{"result_id": "e916d85fd88246ab9ff8f848b59b303c", "data_type": null, "error": null, "metadata": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_loaders/infinite_photon.py", "uuid": "1724235817535", "block_type": "data_loader", "block_uuid": "infinite_photon", "execution_partition": null, "pipeline_uuid": "illuminating_zenith"}, "output": "", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "infinite_photon", "message": "from typing import Dict, List, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch, exceptions\n\nindex_name = \"documents_20240821_5016\"\n\n@data_loader\ndef search(*args, **kwargs) -> List[Dict]:\n    \"\"\"\n    query_embedding: Union[List[int], np.ndarray]\n    \"\"\"\n    \n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    index_name = kwargs.get('index_name', 'documents_20240821_5016')\n    source = kwargs.get('source', \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\")\n    top_k = kwargs.get('top_k', 5)\n    chunk_column = kwargs.get('chunk_column', 'content')\n\n    query_embedding = None\n    if len(args):\n        query_embedding = args[0]\n    if not query_embedding:\n        query_embedding = SAMPLE__EMBEDDINGS[0]\n\n    if isinstance(query_embedding, np.ndarray):\n        query_embedding = query_embedding.tolist()\n\n    script_query = {\n        \"script_score\": {\n            \"query\": {\"match_all\": {}},\n            \"script\": {\n                \"source\": source,\n                \"params\": {\"query_vector\": query_embedding},\n            }\n        }\n    }\n\n    print(\"Sending script query:\", script_query)\n\n    es_client = Elasticsearch(connection_string)\n    \n    try:\n        response = es_client.search(\n            index=index_name,\n            body={\n                \"size\": top_k,\n                \"query\": script_query,\n                \"_source\": [chunk_column],\n            },\n        )\n\n        print(\"Raw response from Elasticsearch:\", response)\n\n        return [hit['_source'][chunk_column] for hit in response['hits']['hits']]\n    \n    except exceptions.BadRequestError as e:\n        print(f\"BadRequestError: {e.info}\")\n        return []\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return []", "message_request_uuid": "1724235817535", "message_uuid": "1cc8590d36064f7a8e0fe56a71d84def", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_loaders/infinite_photon.py", "uuid": "1724235817535"}, "pid": "1cc8590d36064f7a8e0fe56a71d84def", "pid_spawn": null, "source": "infinite_photon", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "infinite_photon"}, "status": "success", "type": "output", "uuid": "infinite_photon", "timestamp": 1724235817572, "output_text": ""}
