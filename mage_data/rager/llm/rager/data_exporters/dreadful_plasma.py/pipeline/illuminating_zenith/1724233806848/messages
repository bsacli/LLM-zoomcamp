{"result_id": "a8fae8ce4d16423fb3ea9c44bbf68d5e", "data_type": "text/plain", "error": null, "metadata": null, "output": "index name: documents_20240821_5013\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233813057, "output_text": "index name: documents_20240821_5013\n"}
{"result_id": "c6ffafea112d42169b0e7700c6062f09", "data_type": "text/plain", "error": null, "metadata": null, "output": "Connecting to Elasticsearch at http://elasticsearch:9200\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233813128, "output_text": "Connecting to Elasticsearch at http://elasticsearch:9200\n"}
{"result_id": "855077483a36416cb13957f3ac5982d9", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index created with properties: {'settings': {'number_of_shards': 1, 'number_of_replicas': 0}, 'mappings': {'properties': {'text': {'type': 'text'}, 'section': {'type': 'text'}, 'question': {'type': 'text'}, 'course': {'type': 'keyword'}, 'document_id': {'type': 'keyword'}}}}\nEmbedding dimensions: 0\nIndexing 86 documents to Elasticsearch index documents_20240821_5013\nIndexing document c68e230a\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233813837, "output_text": "Index created with properties: {'settings': {'number_of_shards': 1, 'number_of_replicas': 0}, 'mappings': {'properties': {'text': {'type': 'text'}, 'section': {'type': 'text'}, 'question': {'type': 'text'}, 'course': {'type': 'keyword'}, 'document_id': {'type': 'keyword'}}}}\nEmbedding dimensions: 0\nIndexing 86 documents to Elasticsearch index documents_20240821_5013\nIndexing document c68e230a\n"}
{"result_id": "fdd30290f2264ee1ad245f5aca0b5626", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 4371c9f8\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814049, "output_text": "Index name documents_20240821_5013\nIndexing document 4371c9f8\n"}
{"result_id": "123d10a3930644dc833b1c21ef80b368", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document f6479ef1\nIndex name documents_20240821_5013\nIndexing document 80ce43fb\nIndex name documents_20240821_5013\nIndexing document 1b550c84\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814108, "output_text": "Index name documents_20240821_5013\nIndexing document f6479ef1\nIndex name documents_20240821_5013\nIndexing document 80ce43fb\nIndex name documents_20240821_5013\nIndexing document 1b550c84\n"}
{"result_id": "8fd2057565964d06a06c2c6bc2e2d6da", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document e9a32294\nIndex name documents_20240821_5013\nIndexing document 09978d0b\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814164, "output_text": "Index name documents_20240821_5013\nIndexing document e9a32294\nIndex name documents_20240821_5013\nIndexing document 09978d0b\n"}
{"result_id": "c4fa62c0cdca4c9ca42ad4f91c475ee8", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document d16050bc\nIndex name documents_20240821_5013\nIndexing document 38f32ebf\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814219, "output_text": "Index name documents_20240821_5013\nIndexing document d16050bc\nIndex name documents_20240821_5013\nIndexing document 38f32ebf\n"}
{"result_id": "979789e336704adfaf1b2315cafd155a", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 77a66e50\nIndex name documents_20240821_5013\nIndexing document cee5e0eb\nIndex name documents_20240821_5013\nIndexing document d298b3b8\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814277, "output_text": "Index name documents_20240821_5013\nIndexing document 77a66e50\nIndex name documents_20240821_5013\nIndexing document cee5e0eb\nIndex name documents_20240821_5013\nIndexing document d298b3b8\n"}
{"result_id": "71def6d96668467d8a7aee4f97f3b8bc", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document f0546f2b\nIndex name documents_20240821_5013\nIndexing document 2a1a8a3e\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814332, "output_text": "Index name documents_20240821_5013\nIndexing document f0546f2b\nIndex name documents_20240821_5013\nIndexing document 2a1a8a3e\n"}
{"result_id": "eb17c6bc44174cc482c969d904d4ab6a", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document d4a6eaaf\nIndex name documents_20240821_5013\nIndexing document 7494734a\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814388, "output_text": "Index name documents_20240821_5013\nIndexing document d4a6eaaf\nIndex name documents_20240821_5013\nIndexing document 7494734a\n"}
{"result_id": "f67858708f234f7fa87b37bb15a08c26", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document cdd66509\nIndex name documents_20240821_5013\nIndexing document 3d6f30b1\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814444, "output_text": "Index name documents_20240821_5013\nIndexing document cdd66509\nIndex name documents_20240821_5013\nIndexing document 3d6f30b1\n"}
{"result_id": "92c6565ec6c1412c958bbb83a930dc2c", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 6f455642\nIndex name documents_20240821_5013\nIndexing document 337f413b\nIndex name documents_20240821_5013\nIndexing document db8d0395\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814501, "output_text": "Index name documents_20240821_5013\nIndexing document 6f455642\nIndex name documents_20240821_5013\nIndexing document 337f413b\nIndex name documents_20240821_5013\nIndexing document db8d0395\n"}
{"result_id": "e0b81af6d65c47a585fa500ddf081143", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document bf82d74b\nIndex name documents_20240821_5013\nIndexing document 0bd79aa4\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814558, "output_text": "Index name documents_20240821_5013\nIndexing document bf82d74b\nIndex name documents_20240821_5013\nIndexing document 0bd79aa4\n"}
{"result_id": "84e64aef5a964ccfbec44af90a4f4ed4", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 9f88afcf\nIndex name documents_20240821_5013\nIndexing document 67d47c7c\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814613, "output_text": "Index name documents_20240821_5013\nIndexing document 9f88afcf\nIndex name documents_20240821_5013\nIndexing document 67d47c7c\n"}
{"result_id": "e17f9c8d635f442d82b584f1b4613fcc", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 00066365\nIndex name documents_20240821_5013\nIndexing document 31550c6e\nIndex name documents_20240821_5013\nIndexing document 314ce357\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814671, "output_text": "Index name documents_20240821_5013\nIndexing document 00066365\nIndex name documents_20240821_5013\nIndexing document 31550c6e\nIndex name documents_20240821_5013\nIndexing document 314ce357\n"}
{"result_id": "ba7f86aaa8b04f09889e272a9cb740ec", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 5c4b4ac0\nIndex name documents_20240821_5013\nIndexing document 8069c479\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814726, "output_text": "Index name documents_20240821_5013\nIndexing document 5c4b4ac0\nIndex name documents_20240821_5013\nIndexing document 8069c479\n"}
{"result_id": "3a361bdcb1c2490d9a86b308514b3938", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 52e06f30\nIndex name documents_20240821_5013\nIndexing document 2dba2f3a\nIndex name documents_20240821_5013\nIndexing document 54f82fe1\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814782, "output_text": "Index name documents_20240821_5013\nIndexing document 52e06f30\nIndex name documents_20240821_5013\nIndexing document 2dba2f3a\nIndex name documents_20240821_5013\nIndexing document 54f82fe1\n"}
{"result_id": "756713400dd74693b2eaab6d317bb7b0", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 649a8e1e\nIndex name documents_20240821_5013\nIndexing document 5f483e5f\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814838, "output_text": "Index name documents_20240821_5013\nIndexing document 649a8e1e\nIndex name documents_20240821_5013\nIndexing document 5f483e5f\n"}
{"result_id": "2902c62146aa413f85bf7260bad0fe29", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document d75d67bc\nIndex name documents_20240821_5013\nIndexing document 2a5a20f6\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814896, "output_text": "Index name documents_20240821_5013\nIndexing document d75d67bc\nIndex name documents_20240821_5013\nIndexing document 2a5a20f6\n"}
{"result_id": "e161e9d6b46a410f96f986c4e2589c65", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 88f2a53e\nIndex name documents_20240821_5013\nIndexing document 8db932c5\nIndex name documents_20240821_5013\nIndexing document 83c862b5\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233814953, "output_text": "Index name documents_20240821_5013\nIndexing document 88f2a53e\nIndex name documents_20240821_5013\nIndexing document 8db932c5\nIndex name documents_20240821_5013\nIndexing document 83c862b5\n"}
{"result_id": "a26f39aee5684c9583bc17156e2d30d0", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 5ac13f3f\nIndex name documents_20240821_5013\nIndexing document 686f35bf\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815009, "output_text": "Index name documents_20240821_5013\nIndexing document 5ac13f3f\nIndex name documents_20240821_5013\nIndexing document 686f35bf\n"}
{"result_id": "deee8d783d5540e8b6356427baa7e96e", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document ddc3956d\nIndex name documents_20240821_5013\nIndexing document 1a03bc51\nIndex name documents_20240821_5013\nIndexing document b53ac115\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815066, "output_text": "Index name documents_20240821_5013\nIndexing document ddc3956d\nIndex name documents_20240821_5013\nIndexing document 1a03bc51\nIndex name documents_20240821_5013\nIndexing document b53ac115\n"}
{"result_id": "19b58827cec94b1f85a0d4aade887bbd", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 13c59ddd\nIndex name documents_20240821_5013\nIndexing document c865b084\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815122, "output_text": "Index name documents_20240821_5013\nIndexing document 13c59ddd\nIndex name documents_20240821_5013\nIndexing document c865b084\n"}
{"result_id": "8f2a3af489ef46f2b296b58abd5309f1", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 62c7f7fc\nIndex name documents_20240821_5013\nIndexing document e5b25e0d\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815178, "output_text": "Index name documents_20240821_5013\nIndexing document 62c7f7fc\nIndex name documents_20240821_5013\nIndexing document e5b25e0d\n"}
{"result_id": "dd488f2b50b04fbf99c78335c1debca9", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 9389cbcc\nIndex name documents_20240821_5013\nIndexing document b3d0f65a\nIndex name documents_20240821_5013\nIndexing document 8e9bc583\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815236, "output_text": "Index name documents_20240821_5013\nIndexing document 9389cbcc\nIndex name documents_20240821_5013\nIndexing document b3d0f65a\nIndex name documents_20240821_5013\nIndexing document 8e9bc583\n"}
{"result_id": "1ba9996afb8843528c3d85920e190062", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 475620b3\nIndex name documents_20240821_5013\nIndexing document 081dcad1\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815291, "output_text": "Index name documents_20240821_5013\nIndexing document 475620b3\nIndex name documents_20240821_5013\nIndexing document 081dcad1\n"}
{"result_id": "5087639b8b3f490cb418f915c16d4c61", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document ad382fe2\nIndex name documents_20240821_5013\nIndexing document 0c74295e\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815347, "output_text": "Index name documents_20240821_5013\nIndexing document ad382fe2\nIndex name documents_20240821_5013\nIndexing document 0c74295e\n"}
{"result_id": "e8d328ee80c74eab9c38eb06f568b070", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 99dd2655\nIndex name documents_20240821_5013\nIndexing document 65ce9a67\nIndex name documents_20240821_5013\nIndexing document 3762c39c\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815404, "output_text": "Index name documents_20240821_5013\nIndexing document 99dd2655\nIndex name documents_20240821_5013\nIndexing document 65ce9a67\nIndex name documents_20240821_5013\nIndexing document 3762c39c\n"}
{"result_id": "b03676ed938847a1a9f2a9957e8da8d9", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document c2567142\nIndex name documents_20240821_5013\nIndexing document a250a9c8\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815460, "output_text": "Index name documents_20240821_5013\nIndexing document c2567142\nIndex name documents_20240821_5013\nIndexing document a250a9c8\n"}
{"result_id": "018f887b7886471c965219a9e83eecb4", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 7122e033\nIndex name documents_20240821_5013\nIndexing document c3c44bce\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815515, "output_text": "Index name documents_20240821_5013\nIndexing document 7122e033\nIndex name documents_20240821_5013\nIndexing document c3c44bce\n"}
{"result_id": "d1830ce5831546418bf6703f55c6fb68", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document e76d1de6\nIndex name documents_20240821_5013\nIndexing document 9aaceffd\nIndex name documents_20240821_5013\nIndexing document 0bd79aa4\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815574, "output_text": "Index name documents_20240821_5013\nIndexing document e76d1de6\nIndex name documents_20240821_5013\nIndexing document 9aaceffd\nIndex name documents_20240821_5013\nIndexing document 0bd79aa4\n"}
{"result_id": "7a91a229a38c4c12b88fccfc3f85282c", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 0bd79aa4\nIndex name documents_20240821_5013\nIndexing document f90fbcbe\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815630, "output_text": "Index name documents_20240821_5013\nIndexing document 0bd79aa4\nIndex name documents_20240821_5013\nIndexing document f90fbcbe\n"}
{"result_id": "52f9c250eea44aefa1226833dfa66637", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 0bd79aa4\nIndex name documents_20240821_5013\nIndexing document 2d527638\nIndex name documents_20240821_5013\nIndexing document 52a87d01\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815688, "output_text": "Index name documents_20240821_5013\nIndexing document 0bd79aa4\nIndex name documents_20240821_5013\nIndexing document 2d527638\nIndex name documents_20240821_5013\nIndexing document 52a87d01\n"}
{"result_id": "01fd0499be7b46689943ab10f35702b5", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 2ac4d9eb\nIndex name documents_20240821_5013\nIndexing document 58bf6255\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815744, "output_text": "Index name documents_20240821_5013\nIndexing document 2ac4d9eb\nIndex name documents_20240821_5013\nIndexing document 58bf6255\n"}
{"result_id": "dc3b2ac6477e4fabbd75303004e511ac", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document ddfdc850\nIndex name documents_20240821_5013\nIndexing document 0bd79aa4\nIndex name documents_20240821_5013\nIndexing document 7ba497ba\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815800, "output_text": "Index name documents_20240821_5013\nIndexing document ddfdc850\nIndex name documents_20240821_5013\nIndexing document 0bd79aa4\nIndex name documents_20240821_5013\nIndexing document 7ba497ba\n"}
{"result_id": "f4ee633e777f4beca1cdc825c5babb10", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document ff743e7a\nIndex name documents_20240821_5013\nIndexing document 204e5cf4\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815856, "output_text": "Index name documents_20240821_5013\nIndexing document ff743e7a\nIndex name documents_20240821_5013\nIndexing document 204e5cf4\n"}
{"result_id": "72e8988470a340928db28d3217707a52", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document ae18f6ef\nIndex name documents_20240821_5013\nIndexing document 5632dcc7\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815913, "output_text": "Index name documents_20240821_5013\nIndexing document ae18f6ef\nIndex name documents_20240821_5013\nIndexing document 5632dcc7\n"}
{"result_id": "ae681738723e47649184225a1d609be8", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 7b6376dc\nIndex name documents_20240821_5013\nIndexing document 1a57f8dc\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233815970, "output_text": "Index name documents_20240821_5013\nIndexing document 7b6376dc\nIndex name documents_20240821_5013\nIndexing document 1a57f8dc\n"}
{"result_id": "ae32d51ed21047f7a51898d0d261de68", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 5d7ccad9\nIndex name documents_20240821_5013\nIndexing document 665709ee\nIndex name documents_20240821_5013\nIndexing document 0bd79aa4\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233816028, "output_text": "Index name documents_20240821_5013\nIndexing document 5d7ccad9\nIndex name documents_20240821_5013\nIndexing document 665709ee\nIndex name documents_20240821_5013\nIndexing document 0bd79aa4\n"}
{"result_id": "2b9dcf3c2395475695102c8bcfff4066", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5013\nIndexing document 21f657ce\nIndex name documents_20240821_5013\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233816086, "output_text": "Index name documents_20240821_5013\nIndexing document 21f657ce\nIndex name documents_20240821_5013\n"}
{"result_id": "02641d2515da44cabc835aac062ff66a", "data_type": null, "error": null, "metadata": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848", "block_type": "data_exporter", "block_uuid": "dreadful_plasma", "execution_partition": null, "pipeline_uuid": "illuminating_zenith"}, "output": "", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "32f1f06167eb47e6b34fa1fb65bab886", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "32f1f06167eb47e6b34fa1fb65bab886", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "success", "type": "output", "uuid": "dreadful_plasma", "timestamp": 1724233816091, "output_text": ""}
{"result_id": "98a189b50a1f4ad8b63e9f8fb4a0d340", "data_type": "text/plain", "error": null, "metadata": null, "output": "index name: documents_20240821_5016\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233816170, "output_text": "index name: documents_20240821_5016\n"}
{"result_id": "f9fafe35a1044699bdf0c8676aafc638", "data_type": "text/plain", "error": null, "metadata": null, "output": "Connecting to Elasticsearch at http://elasticsearch:9200\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233816233, "output_text": "Connecting to Elasticsearch at http://elasticsearch:9200\n"}
{"result_id": "fa7af2959bf54beeadabdfa6b0bdc7ee", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index created with properties: {'settings': {'number_of_shards': 1, 'number_of_replicas': 0}, 'mappings': {'properties': {'text': {'type': 'text'}, 'section': {'type': 'text'}, 'question': {'type': 'text'}, 'course': {'type': 'keyword'}, 'document_id': {'type': 'keyword'}}}}\nEmbedding dimensions: 0\nIndexing 86 documents to Elasticsearch index documents_20240821_5016\nIndexing document c68e230a\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233816742, "output_text": "Index created with properties: {'settings': {'number_of_shards': 1, 'number_of_replicas': 0}, 'mappings': {'properties': {'text': {'type': 'text'}, 'section': {'type': 'text'}, 'question': {'type': 'text'}, 'course': {'type': 'keyword'}, 'document_id': {'type': 'keyword'}}}}\nEmbedding dimensions: 0\nIndexing 86 documents to Elasticsearch index documents_20240821_5016\nIndexing document c68e230a\n"}
{"result_id": "b05a67fba43746a9b3fa61eb70ff311d", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 4371c9f8\nIndex name documents_20240821_5016\nIndexing document f6479ef1\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233816898, "output_text": "Index name documents_20240821_5016\nIndexing document 4371c9f8\nIndex name documents_20240821_5016\nIndexing document f6479ef1\n"}
{"result_id": "71510eb694c045d7a5defe54479fbd8f", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 80ce43fb\nIndex name documents_20240821_5016\nIndexing document 1b550c84\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233816954, "output_text": "Index name documents_20240821_5016\nIndexing document 80ce43fb\nIndex name documents_20240821_5016\nIndexing document 1b550c84\n"}
{"result_id": "428d50cb12614d74aa07197cb7e29f02", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document e9a32294\nIndex name documents_20240821_5016\nIndexing document 09978d0b\nIndex name documents_20240821_5016\nIndexing document d16050bc\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817012, "output_text": "Index name documents_20240821_5016\nIndexing document e9a32294\nIndex name documents_20240821_5016\nIndexing document 09978d0b\nIndex name documents_20240821_5016\nIndexing document d16050bc\n"}
{"result_id": "a514893f276743b18cbb0c9682b70e07", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 38f32ebf\nIndex name documents_20240821_5016\nIndexing document 77a66e50\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817068, "output_text": "Index name documents_20240821_5016\nIndexing document 38f32ebf\nIndex name documents_20240821_5016\nIndexing document 77a66e50\n"}
{"result_id": "970d402fd96f4f008448275e6de4e599", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document cee5e0eb\nIndex name documents_20240821_5016\nIndexing document d298b3b8\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817124, "output_text": "Index name documents_20240821_5016\nIndexing document cee5e0eb\nIndex name documents_20240821_5016\nIndexing document d298b3b8\n"}
{"result_id": "0c5b0f8869504b5d9b59ef9e1884d6f0", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document f0546f2b\nIndex name documents_20240821_5016\nIndexing document 2a1a8a3e\nIndex name documents_20240821_5016\nIndexing document d4a6eaaf\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817182, "output_text": "Index name documents_20240821_5016\nIndexing document f0546f2b\nIndex name documents_20240821_5016\nIndexing document 2a1a8a3e\nIndex name documents_20240821_5016\nIndexing document d4a6eaaf\n"}
{"result_id": "6f1521bf380248ecab03d84f57945759", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 7494734a\nIndex name documents_20240821_5016\nIndexing document cdd66509\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817238, "output_text": "Index name documents_20240821_5016\nIndexing document 7494734a\nIndex name documents_20240821_5016\nIndexing document cdd66509\n"}
{"result_id": "daeee5c44c9a45cabcc98a5fe8ef6802", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 3d6f30b1\nIndex name documents_20240821_5016\nIndexing document 6f455642\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817294, "output_text": "Index name documents_20240821_5016\nIndexing document 3d6f30b1\nIndex name documents_20240821_5016\nIndexing document 6f455642\n"}
{"result_id": "3e4c6287f3264a4d9c3dd27719724d21", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 337f413b\nIndex name documents_20240821_5016\nIndexing document db8d0395\nIndex name documents_20240821_5016\nIndexing document bf82d74b\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817352, "output_text": "Index name documents_20240821_5016\nIndexing document 337f413b\nIndex name documents_20240821_5016\nIndexing document db8d0395\nIndex name documents_20240821_5016\nIndexing document bf82d74b\n"}
{"result_id": "4ecf00d646614ea6ab7bf301920d7f26", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 0bd79aa4\nIndex name documents_20240821_5016\nIndexing document 9f88afcf\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817409, "output_text": "Index name documents_20240821_5016\nIndexing document 0bd79aa4\nIndex name documents_20240821_5016\nIndexing document 9f88afcf\n"}
{"result_id": "5be648f9d9734132bcb2f149e63c5729", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 67d47c7c\nIndex name documents_20240821_5016\nIndexing document 00066365\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817465, "output_text": "Index name documents_20240821_5016\nIndexing document 67d47c7c\nIndex name documents_20240821_5016\nIndexing document 00066365\n"}
{"result_id": "ea075b1848a84986a12d6b7a6228468a", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 31550c6e\nIndex name documents_20240821_5016\nIndexing document 314ce357\nIndex name documents_20240821_5016\nIndexing document 5c4b4ac0\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817521, "output_text": "Index name documents_20240821_5016\nIndexing document 31550c6e\nIndex name documents_20240821_5016\nIndexing document 314ce357\nIndex name documents_20240821_5016\nIndexing document 5c4b4ac0\n"}
{"result_id": "0bb94bbe2acf48b9bddb44ac492b7762", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 8069c479\nIndex name documents_20240821_5016\nIndexing document 52e06f30\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817577, "output_text": "Index name documents_20240821_5016\nIndexing document 8069c479\nIndex name documents_20240821_5016\nIndexing document 52e06f30\n"}
{"result_id": "5b19e79596384f5398b72e3675393402", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 2dba2f3a\nIndex name documents_20240821_5016\nIndexing document 54f82fe1\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817633, "output_text": "Index name documents_20240821_5016\nIndexing document 2dba2f3a\nIndex name documents_20240821_5016\nIndexing document 54f82fe1\n"}
{"result_id": "e254879762f0413a88a263b6c2a4683f", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 649a8e1e\nIndex name documents_20240821_5016\nIndexing document 5f483e5f\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817691, "output_text": "Index name documents_20240821_5016\nIndexing document 649a8e1e\nIndex name documents_20240821_5016\nIndexing document 5f483e5f\n"}
{"result_id": "bb4014b114e34f3cb2410e377fac89f1", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document d75d67bc\nIndex name documents_20240821_5016\nIndexing document 2a5a20f6\nIndex name documents_20240821_5016\nIndexing document 88f2a53e\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817749, "output_text": "Index name documents_20240821_5016\nIndexing document d75d67bc\nIndex name documents_20240821_5016\nIndexing document 2a5a20f6\nIndex name documents_20240821_5016\nIndexing document 88f2a53e\n"}
{"result_id": "dbea94d0e3eb4018b9ccf516d54467a9", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 8db932c5\nIndex name documents_20240821_5016\nIndexing document 83c862b5\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817806, "output_text": "Index name documents_20240821_5016\nIndexing document 8db932c5\nIndex name documents_20240821_5016\nIndexing document 83c862b5\n"}
{"result_id": "e327379b4c7945379d860874f37c1b97", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 5ac13f3f\nIndex name documents_20240821_5016\nIndexing document 686f35bf\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817862, "output_text": "Index name documents_20240821_5016\nIndexing document 5ac13f3f\nIndex name documents_20240821_5016\nIndexing document 686f35bf\n"}
{"result_id": "bd0ed259876244c086f43b385e6c5cfe", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document ddc3956d\nIndex name documents_20240821_5016\nIndexing document 1a03bc51\nIndex name documents_20240821_5016\nIndexing document b53ac115\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817920, "output_text": "Index name documents_20240821_5016\nIndexing document ddc3956d\nIndex name documents_20240821_5016\nIndexing document 1a03bc51\nIndex name documents_20240821_5016\nIndexing document b53ac115\n"}
{"result_id": "bedd5c080f764c2c9ad9773117a08429", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 13c59ddd\nIndex name documents_20240821_5016\nIndexing document c865b084\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233817976, "output_text": "Index name documents_20240821_5016\nIndexing document 13c59ddd\nIndex name documents_20240821_5016\nIndexing document c865b084\n"}
{"result_id": "6b9029951f16434aaa8b35a5e0f721f1", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 62c7f7fc\nIndex name documents_20240821_5016\nIndexing document e5b25e0d\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818032, "output_text": "Index name documents_20240821_5016\nIndexing document 62c7f7fc\nIndex name documents_20240821_5016\nIndexing document e5b25e0d\n"}
{"result_id": "c9d06a0858d24ee58891744654dd439d", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 9389cbcc\nIndex name documents_20240821_5016\nIndexing document b3d0f65a\nIndex name documents_20240821_5016\nIndexing document 8e9bc583\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818089, "output_text": "Index name documents_20240821_5016\nIndexing document 9389cbcc\nIndex name documents_20240821_5016\nIndexing document b3d0f65a\nIndex name documents_20240821_5016\nIndexing document 8e9bc583\n"}
{"result_id": "ea09a7719aba40a7b5b272d626cd71c0", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 475620b3\nIndex name documents_20240821_5016\nIndexing document 081dcad1\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818145, "output_text": "Index name documents_20240821_5016\nIndexing document 475620b3\nIndex name documents_20240821_5016\nIndexing document 081dcad1\n"}
{"result_id": "c341835f7052499ca10fe2250e8cecdb", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document ad382fe2\nIndex name documents_20240821_5016\nIndexing document 0c74295e\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818200, "output_text": "Index name documents_20240821_5016\nIndexing document ad382fe2\nIndex name documents_20240821_5016\nIndexing document 0c74295e\n"}
{"result_id": "8302c10930a54e5e9c675934b32539ee", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 99dd2655\nIndex name documents_20240821_5016\nIndexing document 65ce9a67\nIndex name documents_20240821_5016\nIndexing document 3762c39c\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818257, "output_text": "Index name documents_20240821_5016\nIndexing document 99dd2655\nIndex name documents_20240821_5016\nIndexing document 65ce9a67\nIndex name documents_20240821_5016\nIndexing document 3762c39c\n"}
{"result_id": "f3aeaf45830149ba8cae296ab5eaff34", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document c2567142\nIndex name documents_20240821_5016\nIndexing document a250a9c8\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818314, "output_text": "Index name documents_20240821_5016\nIndexing document c2567142\nIndex name documents_20240821_5016\nIndexing document a250a9c8\n"}
{"result_id": "498d3947bfb647b68e64c69f6ef1206c", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 7122e033\nIndex name documents_20240821_5016\nIndexing document c3c44bce\nIndex name documents_20240821_5016\nIndexing document e76d1de6\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818370, "output_text": "Index name documents_20240821_5016\nIndexing document 7122e033\nIndex name documents_20240821_5016\nIndexing document c3c44bce\nIndex name documents_20240821_5016\nIndexing document e76d1de6\n"}
{"result_id": "7ad712d4042d45f6b7cdce0651953d37", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 9aaceffd\nIndex name documents_20240821_5016\nIndexing document 0bd79aa4\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818427, "output_text": "Index name documents_20240821_5016\nIndexing document 9aaceffd\nIndex name documents_20240821_5016\nIndexing document 0bd79aa4\n"}
{"result_id": "ce44f00a78fb4cc894b11daa2283a2d6", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 0bd79aa4\nIndex name documents_20240821_5016\nIndexing document f90fbcbe\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818483, "output_text": "Index name documents_20240821_5016\nIndexing document 0bd79aa4\nIndex name documents_20240821_5016\nIndexing document f90fbcbe\n"}
{"result_id": "3a5fb6b180084cd4be874562346cec20", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 0bd79aa4\nIndex name documents_20240821_5016\nIndexing document 2d527638\nIndex name documents_20240821_5016\nIndexing document 52a87d01\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818540, "output_text": "Index name documents_20240821_5016\nIndexing document 0bd79aa4\nIndex name documents_20240821_5016\nIndexing document 2d527638\nIndex name documents_20240821_5016\nIndexing document 52a87d01\n"}
{"result_id": "456882bc4f9f468a944b6b682ed02ce8", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 2ac4d9eb\nIndex name documents_20240821_5016\nIndexing document 58bf6255\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818596, "output_text": "Index name documents_20240821_5016\nIndexing document 2ac4d9eb\nIndex name documents_20240821_5016\nIndexing document 58bf6255\n"}
{"result_id": "951097e22e5f4e3dbf8346d13370d278", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document ddfdc850\nIndex name documents_20240821_5016\nIndexing document 0bd79aa4\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818652, "output_text": "Index name documents_20240821_5016\nIndexing document ddfdc850\nIndex name documents_20240821_5016\nIndexing document 0bd79aa4\n"}
{"result_id": "898e7c70c98d4e1c92937b3e10249d23", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 7ba497ba\nIndex name documents_20240821_5016\nIndexing document ff743e7a\nIndex name documents_20240821_5016\nIndexing document 204e5cf4\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818709, "output_text": "Index name documents_20240821_5016\nIndexing document 7ba497ba\nIndex name documents_20240821_5016\nIndexing document ff743e7a\nIndex name documents_20240821_5016\nIndexing document 204e5cf4\n"}
{"result_id": "75df997dfd18431d943e96b9048c499b", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document ae18f6ef\nIndex name documents_20240821_5016\nIndexing document 5632dcc7\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818765, "output_text": "Index name documents_20240821_5016\nIndexing document ae18f6ef\nIndex name documents_20240821_5016\nIndexing document 5632dcc7\n"}
{"result_id": "c46071396f8943a4b9278e770c069fd1", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 7b6376dc\nIndex name documents_20240821_5016\nIndexing document 1a57f8dc\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818821, "output_text": "Index name documents_20240821_5016\nIndexing document 7b6376dc\nIndex name documents_20240821_5016\nIndexing document 1a57f8dc\n"}
{"result_id": "e632441da75f43e5a3f7b1ce1f052a32", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 5d7ccad9\nIndex name documents_20240821_5016\nIndexing document 665709ee\nIndex name documents_20240821_5016\nIndexing document 0bd79aa4\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818878, "output_text": "Index name documents_20240821_5016\nIndexing document 5d7ccad9\nIndex name documents_20240821_5016\nIndexing document 665709ee\nIndex name documents_20240821_5016\nIndexing document 0bd79aa4\n"}
{"result_id": "93546940a6dd4ad3a6f310193ff4e3e9", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_5016\nIndexing document 21f657ce\nIndex name documents_20240821_5016\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724233818935, "output_text": "Index name documents_20240821_5016\nIndexing document 21f657ce\nIndex name documents_20240821_5016\n"}
{"result_id": "de2f42aa522747b08946b702bf35a185", "data_type": null, "error": null, "metadata": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848", "block_type": "data_exporter", "block_uuid": "dreadful_plasma", "execution_partition": null, "pipeline_uuid": "illuminating_zenith"}, "output": "", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724233806848", "message_uuid": "e2da473b119640c0bcae5089ad753d21", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724233806848"}, "pid": "e2da473b119640c0bcae5089ad753d21", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "success", "type": "output", "uuid": "dreadful_plasma", "timestamp": 1724233818940, "output_text": ""}
