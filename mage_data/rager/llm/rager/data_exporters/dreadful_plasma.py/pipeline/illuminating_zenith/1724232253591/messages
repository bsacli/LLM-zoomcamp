{"result_id": "dbd3cc74e1c24541a4cc82e4d53e08d5", "data_type": "text/plain", "error": null, "metadata": null, "output": "index name: documents_20240821_2419\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232259608, "output_text": "index name: documents_20240821_2419\n"}
{"result_id": "4d713a0efa2f4438a872e1ff280af68c", "data_type": "text/plain", "error": null, "metadata": null, "output": "Connecting to Elasticsearch at http://elasticsearch:9200\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232259730, "output_text": "Connecting to Elasticsearch at http://elasticsearch:9200\n"}
{"result_id": "c4e1b69d75094b01902796b2d160d969", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index created with properties: {'settings': {'number_of_shards': 1, 'number_of_replicas': 0}, 'mappings': {'properties': {'text': {'type': 'text'}, 'section': {'type': 'text'}, 'question': {'type': 'text'}, 'course': {'type': 'keyword'}, 'document_id': {'type': 'keyword'}}}}\nEmbedding dimensions: 0\nIndexing 86 documents to Elasticsearch index documents_20240821_2419\nIndexing document c68e230a\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232260288, "output_text": "Index created with properties: {'settings': {'number_of_shards': 1, 'number_of_replicas': 0}, 'mappings': {'properties': {'text': {'type': 'text'}, 'section': {'type': 'text'}, 'question': {'type': 'text'}, 'course': {'type': 'keyword'}, 'document_id': {'type': 'keyword'}}}}\nEmbedding dimensions: 0\nIndexing 86 documents to Elasticsearch index documents_20240821_2419\nIndexing document c68e230a\n"}
{"result_id": "1aeae9fc51a241679d71abacb4bb2c84", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 4371c9f8\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232260444, "output_text": "Index name documents_20240821_2419\nIndexing document 4371c9f8\n"}
{"result_id": "6aaa98f436444d30a5c30414a1ccceea", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document f6479ef1\nIndex name documents_20240821_2419\nIndexing document 80ce43fb\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232260500, "output_text": "Index name documents_20240821_2419\nIndexing document f6479ef1\nIndex name documents_20240821_2419\nIndexing document 80ce43fb\n"}
{"result_id": "090f8541ef324ffc9c008a74e17e1696", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 1b550c84\nIndex name documents_20240821_2419\nIndexing document e9a32294\nIndex name documents_20240821_2419\nIndexing document 09978d0b\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232260556, "output_text": "Index name documents_20240821_2419\nIndexing document 1b550c84\nIndex name documents_20240821_2419\nIndexing document e9a32294\nIndex name documents_20240821_2419\nIndexing document 09978d0b\n"}
{"result_id": "9f2631215e6b45e5933583a441ea89be", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document d16050bc\nIndex name documents_20240821_2419\nIndexing document 38f32ebf\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232260612, "output_text": "Index name documents_20240821_2419\nIndexing document d16050bc\nIndex name documents_20240821_2419\nIndexing document 38f32ebf\n"}
{"result_id": "81e4e0239ca849d39bb6bd98e71d354d", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 77a66e50\nIndex name documents_20240821_2419\nIndexing document cee5e0eb\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232260667, "output_text": "Index name documents_20240821_2419\nIndexing document 77a66e50\nIndex name documents_20240821_2419\nIndexing document cee5e0eb\n"}
{"result_id": "b658d066168e42048352fb9fec080d95", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document d298b3b8\nIndex name documents_20240821_2419\nIndexing document f0546f2b\nIndex name documents_20240821_2419\nIndexing document 2a1a8a3e\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232260727, "output_text": "Index name documents_20240821_2419\nIndexing document d298b3b8\nIndex name documents_20240821_2419\nIndexing document f0546f2b\nIndex name documents_20240821_2419\nIndexing document 2a1a8a3e\n"}
{"result_id": "e86b8fc7e7254386be96f5cdf03f18e3", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document d4a6eaaf\nIndex name documents_20240821_2419\nIndexing document 7494734a\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232260782, "output_text": "Index name documents_20240821_2419\nIndexing document d4a6eaaf\nIndex name documents_20240821_2419\nIndexing document 7494734a\n"}
{"result_id": "2f9b4244558d42e0a27178d046ed80cc", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document cdd66509\nIndex name documents_20240821_2419\nIndexing document 3d6f30b1\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232260838, "output_text": "Index name documents_20240821_2419\nIndexing document cdd66509\nIndex name documents_20240821_2419\nIndexing document 3d6f30b1\n"}
{"result_id": "244d42657b5841e6b1a0283c16ca74d5", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 6f455642\nIndex name documents_20240821_2419\nIndexing document 337f413b\nIndex name documents_20240821_2419\nIndexing document db8d0395\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232260894, "output_text": "Index name documents_20240821_2419\nIndexing document 6f455642\nIndex name documents_20240821_2419\nIndexing document 337f413b\nIndex name documents_20240821_2419\nIndexing document db8d0395\n"}
{"result_id": "b8d1f1c1a1184b9796cd0d8f4db4f2a4", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document bf82d74b\nIndex name documents_20240821_2419\nIndexing document 0bd79aa4\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232260950, "output_text": "Index name documents_20240821_2419\nIndexing document bf82d74b\nIndex name documents_20240821_2419\nIndexing document 0bd79aa4\n"}
{"result_id": "5afca69070c346d58eced2c71462fcd7", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 9f88afcf\nIndex name documents_20240821_2419\nIndexing document 67d47c7c\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261006, "output_text": "Index name documents_20240821_2419\nIndexing document 9f88afcf\nIndex name documents_20240821_2419\nIndexing document 67d47c7c\n"}
{"result_id": "f3b5daeb78e144678dc061fb169a0734", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 00066365\nIndex name documents_20240821_2419\nIndexing document 31550c6e\nIndex name documents_20240821_2419\nIndexing document 314ce357\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261065, "output_text": "Index name documents_20240821_2419\nIndexing document 00066365\nIndex name documents_20240821_2419\nIndexing document 31550c6e\nIndex name documents_20240821_2419\nIndexing document 314ce357\n"}
{"result_id": "cbb4a5e0771f40bd9d6b813606226a79", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 5c4b4ac0\nIndex name documents_20240821_2419\nIndexing document 8069c479\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261121, "output_text": "Index name documents_20240821_2419\nIndexing document 5c4b4ac0\nIndex name documents_20240821_2419\nIndexing document 8069c479\n"}
{"result_id": "81411861cb5b4078ad92a897c1fe2580", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 52e06f30\nIndex name documents_20240821_2419\nIndexing document 2dba2f3a\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261177, "output_text": "Index name documents_20240821_2419\nIndexing document 52e06f30\nIndex name documents_20240821_2419\nIndexing document 2dba2f3a\n"}
{"result_id": "a6102a3d54f748f390acd72c95c3d271", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 54f82fe1\nIndex name documents_20240821_2419\nIndexing document 649a8e1e\nIndex name documents_20240821_2419\nIndexing document 5f483e5f\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261235, "output_text": "Index name documents_20240821_2419\nIndexing document 54f82fe1\nIndex name documents_20240821_2419\nIndexing document 649a8e1e\nIndex name documents_20240821_2419\nIndexing document 5f483e5f\n"}
{"result_id": "70a269edf040459db7fdc68a40a59014", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document d75d67bc\nIndex name documents_20240821_2419\nIndexing document 2a5a20f6\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261291, "output_text": "Index name documents_20240821_2419\nIndexing document d75d67bc\nIndex name documents_20240821_2419\nIndexing document 2a5a20f6\n"}
{"result_id": "13fc6096ef824fd38028d961b8086076", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 88f2a53e\nIndex name documents_20240821_2419\nIndexing document 8db932c5\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261347, "output_text": "Index name documents_20240821_2419\nIndexing document 88f2a53e\nIndex name documents_20240821_2419\nIndexing document 8db932c5\n"}
{"result_id": "2f7d473d082c4833a3afb13b35ac67db", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 83c862b5\nIndex name documents_20240821_2419\nIndexing document 5ac13f3f\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261402, "output_text": "Index name documents_20240821_2419\nIndexing document 83c862b5\nIndex name documents_20240821_2419\nIndexing document 5ac13f3f\n"}
{"result_id": "45a00390883b434691e469f92f2514af", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 686f35bf\nIndex name documents_20240821_2419\nIndexing document ddc3956d\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261458, "output_text": "Index name documents_20240821_2419\nIndexing document 686f35bf\nIndex name documents_20240821_2419\nIndexing document ddc3956d\n"}
{"result_id": "641adaecf94d43bcb42e7f0d1509204b", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 1a03bc51\nIndex name documents_20240821_2419\nIndexing document b53ac115\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261514, "output_text": "Index name documents_20240821_2419\nIndexing document 1a03bc51\nIndex name documents_20240821_2419\nIndexing document b53ac115\n"}
{"result_id": "e814bb55916349d8ba197c74609681ea", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 13c59ddd\nIndex name documents_20240821_2419\nIndexing document c865b084\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261571, "output_text": "Index name documents_20240821_2419\nIndexing document 13c59ddd\nIndex name documents_20240821_2419\nIndexing document c865b084\n"}
{"result_id": "add1fa9bc20745b5ab1b6da1983324b4", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 62c7f7fc\nIndex name documents_20240821_2419\nIndexing document e5b25e0d\nIndex name documents_20240821_2419\nIndexing document 9389cbcc\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261628, "output_text": "Index name documents_20240821_2419\nIndexing document 62c7f7fc\nIndex name documents_20240821_2419\nIndexing document e5b25e0d\nIndex name documents_20240821_2419\nIndexing document 9389cbcc\n"}
{"result_id": "5c9029b046fb440fb9545fb2abdb8c0b", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document b3d0f65a\nIndex name documents_20240821_2419\nIndexing document 8e9bc583\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261684, "output_text": "Index name documents_20240821_2419\nIndexing document b3d0f65a\nIndex name documents_20240821_2419\nIndexing document 8e9bc583\n"}
{"result_id": "c1abeba77b5c4153950e38fe0affb9fa", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 475620b3\nIndex name documents_20240821_2419\nIndexing document 081dcad1\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261739, "output_text": "Index name documents_20240821_2419\nIndexing document 475620b3\nIndex name documents_20240821_2419\nIndexing document 081dcad1\n"}
{"result_id": "7f910e2e29aa4b94a1557bb1108d0ab9", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document ad382fe2\nIndex name documents_20240821_2419\nIndexing document 0c74295e\nIndex name documents_20240821_2419\nIndexing document 99dd2655\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261796, "output_text": "Index name documents_20240821_2419\nIndexing document ad382fe2\nIndex name documents_20240821_2419\nIndexing document 0c74295e\nIndex name documents_20240821_2419\nIndexing document 99dd2655\n"}
{"result_id": "4a4f51b2f386423d8bbcb88106557218", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 65ce9a67\nIndex name documents_20240821_2419\nIndexing document 3762c39c\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261851, "output_text": "Index name documents_20240821_2419\nIndexing document 65ce9a67\nIndex name documents_20240821_2419\nIndexing document 3762c39c\n"}
{"result_id": "948139f2dfc14398b639b12e14d54b2f", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document c2567142\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261907, "output_text": "Index name documents_20240821_2419\nIndexing document c2567142\n"}
{"result_id": "e9be236f5b2544bbaa689ff32efd24f1", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document a250a9c8\nIndex name documents_20240821_2419\nIndexing document 7122e033\nIndex name documents_20240821_2419\nIndexing document c3c44bce\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232261967, "output_text": "Index name documents_20240821_2419\nIndexing document a250a9c8\nIndex name documents_20240821_2419\nIndexing document 7122e033\nIndex name documents_20240821_2419\nIndexing document c3c44bce\n"}
{"result_id": "a968f7c2eab2443fb2b4b98c93d48259", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document e76d1de6\nIndex name documents_20240821_2419\nIndexing document 9aaceffd\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232262024, "output_text": "Index name documents_20240821_2419\nIndexing document e76d1de6\nIndex name documents_20240821_2419\nIndexing document 9aaceffd\n"}
{"result_id": "3c67a811867b4886bb736e75a6c6bc89", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 0bd79aa4\nIndex name documents_20240821_2419\nIndexing document 0bd79aa4\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232262080, "output_text": "Index name documents_20240821_2419\nIndexing document 0bd79aa4\nIndex name documents_20240821_2419\nIndexing document 0bd79aa4\n"}
{"result_id": "e8277ef83e5d4a81a19ac7bd74856b5f", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document f90fbcbe\nIndex name documents_20240821_2419\nIndexing document 0bd79aa4\nIndex name documents_20240821_2419\nIndexing document 2d527638\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232262138, "output_text": "Index name documents_20240821_2419\nIndexing document f90fbcbe\nIndex name documents_20240821_2419\nIndexing document 0bd79aa4\nIndex name documents_20240821_2419\nIndexing document 2d527638\n"}
{"result_id": "ff8ab30b5a5f424dbc8e0aa4e1e08309", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 52a87d01\nIndex name documents_20240821_2419\nIndexing document 2ac4d9eb\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232262195, "output_text": "Index name documents_20240821_2419\nIndexing document 52a87d01\nIndex name documents_20240821_2419\nIndexing document 2ac4d9eb\n"}
{"result_id": "3708386b4cd14e49bef082265cac90e0", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 58bf6255\nIndex name documents_20240821_2419\nIndexing document ddfdc850\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232262252, "output_text": "Index name documents_20240821_2419\nIndexing document 58bf6255\nIndex name documents_20240821_2419\nIndexing document ddfdc850\n"}
{"result_id": "dc513f56b7c24a89849d2369497c090c", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 0bd79aa4\nIndex name documents_20240821_2419\nIndexing document 7ba497ba\nIndex name documents_20240821_2419\nIndexing document ff743e7a\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232262309, "output_text": "Index name documents_20240821_2419\nIndexing document 0bd79aa4\nIndex name documents_20240821_2419\nIndexing document 7ba497ba\nIndex name documents_20240821_2419\nIndexing document ff743e7a\n"}
{"result_id": "76d614c93f644c39966c7469be06e1a9", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 204e5cf4\nIndex name documents_20240821_2419\nIndexing document ae18f6ef\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232262365, "output_text": "Index name documents_20240821_2419\nIndexing document 204e5cf4\nIndex name documents_20240821_2419\nIndexing document ae18f6ef\n"}
{"result_id": "badabe64eeff4dfcb225f2f995d3111e", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 5632dcc7\nIndex name documents_20240821_2419\nIndexing document 7b6376dc\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232262421, "output_text": "Index name documents_20240821_2419\nIndexing document 5632dcc7\nIndex name documents_20240821_2419\nIndexing document 7b6376dc\n"}
{"result_id": "91fc6d2281eb43cca21e07c7ba212987", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 1a57f8dc\nIndex name documents_20240821_2419\nIndexing document 5d7ccad9\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232262477, "output_text": "Index name documents_20240821_2419\nIndexing document 1a57f8dc\nIndex name documents_20240821_2419\nIndexing document 5d7ccad9\n"}
{"result_id": "dd3c684d918e467a8607576923ec8071", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 665709ee\nIndex name documents_20240821_2419\nIndexing document 0bd79aa4\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232262534, "output_text": "Index name documents_20240821_2419\nIndexing document 665709ee\nIndex name documents_20240821_2419\nIndexing document 0bd79aa4\n"}
{"result_id": "ff02b25418ef493e9ebada7e0dbae622", "data_type": "text/plain", "error": null, "metadata": null, "output": "Index name documents_20240821_2419\nIndexing document 21f657ce\nIndex name documents_20240821_2419\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "running", "type": "stdout", "uuid": "dreadful_plasma", "timestamp": 1724232262590, "output_text": "Index name documents_20240821_2419\nIndexing document 21f657ce\nIndex name documents_20240821_2419\n"}
{"result_id": "c999a50f4c284b6795c3c00c090691d0", "data_type": null, "error": null, "metadata": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591", "block_type": "data_exporter", "block_uuid": "dreadful_plasma", "execution_partition": null, "pipeline_uuid": "illuminating_zenith"}, "output": "", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "dreadful_plasma", "message": "from typing import Dict, List, Tuple, Union\n\nimport numpy as np\nfrom elasticsearch import Elasticsearch\n\nif 'data_exporter' not in globals():\n    from mage_ai.data_preparation.decorators import data_exporter\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    from datetime import datetime\n\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    print(\"index name:\", index_name)\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    from mage_ai.data_preparation.variable_manager import set_global_variable\n\n    set_global_variable('illuminating_zenith', 'index_name', index_name) \n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    from elasticsearch import Elasticsearch\n\n    es_client = Elasticsearch(\n        connection_string,\n        timeout=60,  # Increase timeout to 60 seconds\n        max_retries=10,\n        retry_on_timeout=True\n    )\n\n\n    print(f'Connecting to Elasticsearch at {connection_string}')\n\n    index_settings = {\n    \"settings\": {\n        \"number_of_shards\": number_of_shards,\n        \"number_of_replicas\": number_of_replicas\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"text\": {\"type\": \"text\"},\n            \"section\": {\"type\": \"text\"},\n            \"question\": {\"type\": \"text\"},\n            \"course\": {\"type\": \"keyword\"},\n            \"document_id\": {\"type\": \"keyword\"}\n        }\n    }\n}\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name)\n        print('Index created with properties:', index_settings)\n        print('Embedding dimensions:', dimensions)\n\n    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n    for document in documents:\n        print(f'Indexing document {document[\"document_id\"]}')\n\n        es_client.index(index=index_name, document=document)\n        print(f'Index name {index_name}')\n\n        # print(document)", "message_request_uuid": "1724232253591", "message_uuid": "96ece98791f84d10bc1d4441cbf61dbc", "output_manager": {"namespace": "pipeline/illuminating_zenith", "path": "llm/rager/data_exporters/dreadful_plasma.py", "uuid": "1724232253591"}, "pid": "96ece98791f84d10bc1d4441cbf61dbc", "pid_spawn": null, "source": "dreadful_plasma", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "dreadful_plasma"}, "status": "success", "type": "output", "uuid": "dreadful_plasma", "timestamp": 1724232262595, "output_text": ""}
