{"result_id": "171acb89068042a19b208ae7dbf82113", "data_type": null, "error": {"code": "from typing import Dict, List, Union\nimport numpy as np\nfrom elasticsearch import Elasticsearch, exceptions\nfrom datetime import datetime\nfrom mage_ai.data_preparation.variable_manager import set_global_variable\nfrom elasticsearch.helpers import bulk\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    set_global_variable('resonant_kinesis', 'index_name', index_name)\n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    try:\n        es_client = Elasticsearch(connection_string)\n    except exceptions.ConnectionError as e:\n        print(f\"Could not connect to Elasticsearch: {e}\")\n        return\n\n    index_settings = {\n        \"settings\": {\n            \"number_of_shards\": number_of_shards,\n            \"number_of_replicas\": number_of_replicas\n        },\n        \"mappings\": {\n            \"properties\": {\n                \"text\": {\"type\": \"text\"},\n                \"section\": {\"type\": \"text\"},\n                \"question\": {\"type\": \"text\"},\n                \"course\": {\"type\": \"keyword\"},\n                \"document_id\": {\"type\": \"keyword\"},\n                vector_column_name: {\n                    \"type\": \"dense_vector\",\n                    \"dims\": dimensions\n                } if dimensions else {}\n            }\n        }\n    }\n\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name, body=index_settings)\n    else:\n        print(f\"Index {index_name} already exists.\")\n\n    actions = [\n        {\n            \"_index\": index_name,\n            \"_source\": document\n        }\n        for document in documents\n    ]\n\n    try:\n        bulk(es_client, actions)\n    except exceptions.ElasticsearchException as e:\n        print(f\"Error during bulk indexing: {e}\")\n    finally:\n        es_client.close()\n", "code_context": [], "code_context_formatted": [], "error": "BadRequestError(400, 'mapper_parsing_exception', 'No type specified for field [embedding]')", "errors": null, "exception": "BadRequestError: BadRequestError(400, 'mapper_parsing_exception', 'No type specified for field [embedding]')", "line_number": 320, "message": "BadRequestError(400, 'mapper_parsing_exception', 'No type specified for field [embedding]')", "message_formatted": "BadRequestError(400, 'mapper_parsing_exception', 'No type specified for field [embedding]')", "stacktrace": ["Traceback (most recent call last):\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\", line 281, in execute_code_async\n    local_variables = await __modify_and_execute(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\", line 135, in __modify_and_execute\n    raise error\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\", line 117, in __modify_and_execute\n    res = await res\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/environments/setup_helpers.py\", line 48, in execute\n    await block.execute(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1711, in execute\n    await loop.run_in_executor(\n", "  File \"/usr/local/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1688, in execute_sync\n    return __execute()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1665, in __execute\n    raise err\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1567, in __execute\n    output = self.execute_block(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1912, in execute_block\n    outputs = self._execute_block(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 2075, in _execute_block\n    outputs = self.execute_block_function(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 2186, in execute_block_function\n    output = block_function_updated(*input_vars, **runtime_variables)\n", "  File \"<string>\", line 59, in elasticsearch\n", "  File \"/usr/local/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py\", line 414, in wrapped\n    return api(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/elasticsearch/_sync/client/indices.py\", line 517, in create\n    return self.perform_request(  # type: ignore[return-value]\n", "  File \"/usr/local/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py\", line 389, in perform_request\n    return self._client.perform_request(\n", "  File \"/usr/local/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py\", line 320, in perform_request\n    raise HTTP_EXCEPTIONS.get(meta.status, ApiError)(\n", "elasticsearch.BadRequestError: BadRequestError(400, 'mapper_parsing_exception', 'No type specified for field [embedding]')\n"], "stacktrace_formatted": ["\u001b[91mTraceback (most recent call last):\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\"\u001b[0m, \u001b[36mline 281\u001b[0m, \u001b[35min execute_code_async\n    local_variables = await __modify_and_execute(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\"\u001b[0m, \u001b[36mline 135\u001b[0m, \u001b[35min __modify_and_execute\n    raise error\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\"\u001b[0m, \u001b[36mline 117\u001b[0m, \u001b[35min __modify_and_execute\n    res = await res\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/environments/setup_helpers.py\"\u001b[0m, \u001b[36mline 48\u001b[0m, \u001b[35min execute\n    await block.execute(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1711\u001b[0m, \u001b[35min execute\n    await loop.run_in_executor(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/concurrent/futures/thread.py\"\u001b[0m, \u001b[36mline 58\u001b[0m, \u001b[35min run\n    result = self.fn(*self.args, **self.kwargs)\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1688\u001b[0m, \u001b[35min execute_sync\n    return __execute()\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1665\u001b[0m, \u001b[35min __execute\n    raise err\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1567\u001b[0m, \u001b[35min __execute\n    output = self.execute_block(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1912\u001b[0m, \u001b[35min execute_block\n    outputs = self._execute_block(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 2075\u001b[0m, \u001b[35min _execute_block\n    outputs = self.execute_block_function(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 2186\u001b[0m, \u001b[35min execute_block_function\n    output = block_function_updated(*input_vars, **runtime_variables)\n\u001b[0m", "\u001b[34m  File \"<string>\"\u001b[0m, \u001b[36mline 59\u001b[0m, \u001b[35min elasticsearch\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py\"\u001b[0m, \u001b[36mline 414\u001b[0m, \u001b[35min wrapped\n    return api(*args, **kwargs)\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/elasticsearch/_sync/client/indices.py\"\u001b[0m, \u001b[36mline 517\u001b[0m, \u001b[35min create\n    return self.perform_request(  # type: ignore[return-value]\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py\"\u001b[0m, \u001b[36mline 389\u001b[0m, \u001b[35min perform_request\n    return self._client.perform_request(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py\"\u001b[0m, \u001b[36mline 320\u001b[0m, \u001b[35min perform_request\n    raise HTTP_EXCEPTIONS.get(meta.status, ApiError)(\n\u001b[0m", "\u001b[90melasticsearch.BadRequestError: BadRequestError(400, 'mapper_parsing_exception', 'No type specified for field [embedding]')\n\u001b[0m", "\u001b[91mBadRequestError(400, 'mapper_parsing_exception', 'No type specified for field [embedding]')\u001b[0m"], "type": "BadRequestError"}, "metadata": null, "output": null, "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "chromatic_dimension", "message": "from typing import Dict, List, Union\nimport numpy as np\nfrom elasticsearch import Elasticsearch, exceptions\nfrom datetime import datetime\nfrom mage_ai.data_preparation.variable_manager import set_global_variable\nfrom elasticsearch.helpers import bulk\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    set_global_variable('resonant_kinesis', 'index_name', index_name)\n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    try:\n        es_client = Elasticsearch(connection_string)\n    except exceptions.ConnectionError as e:\n        print(f\"Could not connect to Elasticsearch: {e}\")\n        return\n\n    index_settings = {\n        \"settings\": {\n            \"number_of_shards\": number_of_shards,\n            \"number_of_replicas\": number_of_replicas\n        },\n        \"mappings\": {\n            \"properties\": {\n                \"text\": {\"type\": \"text\"},\n                \"section\": {\"type\": \"text\"},\n                \"question\": {\"type\": \"text\"},\n                \"course\": {\"type\": \"keyword\"},\n                \"document_id\": {\"type\": \"keyword\"},\n                vector_column_name: {\n                    \"type\": \"dense_vector\",\n                    \"dims\": dimensions\n                } if dimensions else {}\n            }\n        }\n    }\n\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name, body=index_settings)\n    else:\n        print(f\"Index {index_name} already exists.\")\n\n    actions = [\n        {\n            \"_index\": index_name,\n            \"_source\": document\n        }\n        for document in documents\n    ]\n\n    try:\n        bulk(es_client, actions)\n    except exceptions.ElasticsearchException as e:\n        print(f\"Error during bulk indexing: {e}\")\n    finally:\n        es_client.close()\n", "message_request_uuid": "1724163616308", "message_uuid": "a90dfd3680094fc09733678d3c783acd", "output_manager": {"namespace": "pipeline/resonant_kinesis", "path": "llm/rager/data_exporters/chromatic_dimension.py", "uuid": "1724163616308"}, "pid": "a90dfd3680094fc09733678d3c783acd", "pid_spawn": null, "source": "chromatic_dimension", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "chromatic_dimension"}, "status": "error", "type": "status", "uuid": "chromatic_dimension", "timestamp": 1724163620646, "output_text": null}
{"result_id": "c5cc306768f842dc8858ab37d54a0520", "data_type": null, "error": null, "metadata": {"namespace": "pipeline/resonant_kinesis", "path": "llm/rager/data_exporters/chromatic_dimension.py", "uuid": "1724163616308", "block_type": "data_exporter", "block_uuid": "chromatic_dimension", "execution_partition": null, "pipeline_uuid": "resonant_kinesis"}, "output": "", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "chromatic_dimension", "message": "from typing import Dict, List, Union\nimport numpy as np\nfrom elasticsearch import Elasticsearch, exceptions\nfrom datetime import datetime\nfrom mage_ai.data_preparation.variable_manager import set_global_variable\nfrom elasticsearch.helpers import bulk\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    set_global_variable('resonant_kinesis', 'index_name', index_name)\n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    try:\n        es_client = Elasticsearch(connection_string)\n    except exceptions.ConnectionError as e:\n        print(f\"Could not connect to Elasticsearch: {e}\")\n        return\n\n    index_settings = {\n        \"settings\": {\n            \"number_of_shards\": number_of_shards,\n            \"number_of_replicas\": number_of_replicas\n        },\n        \"mappings\": {\n            \"properties\": {\n                \"text\": {\"type\": \"text\"},\n                \"section\": {\"type\": \"text\"},\n                \"question\": {\"type\": \"text\"},\n                \"course\": {\"type\": \"keyword\"},\n                \"document_id\": {\"type\": \"keyword\"},\n                vector_column_name: {\n                    \"type\": \"dense_vector\",\n                    \"dims\": dimensions\n                } if dimensions else {}\n            }\n        }\n    }\n\n    if not es_client.indices.exists(index=index_name):\n        es_client.indices.create(index=index_name, body=index_settings)\n    else:\n        print(f\"Index {index_name} already exists.\")\n\n    actions = [\n        {\n            \"_index\": index_name,\n            \"_source\": document\n        }\n        for document in documents\n    ]\n\n    try:\n        bulk(es_client, actions)\n    except exceptions.ElasticsearchException as e:\n        print(f\"Error during bulk indexing: {e}\")\n    finally:\n        es_client.close()\n", "message_request_uuid": "1724163616308", "message_uuid": "a90dfd3680094fc09733678d3c783acd", "output_manager": {"namespace": "pipeline/resonant_kinesis", "path": "llm/rager/data_exporters/chromatic_dimension.py", "uuid": "1724163616308"}, "pid": "a90dfd3680094fc09733678d3c783acd", "pid_spawn": null, "source": "chromatic_dimension", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "chromatic_dimension"}, "status": "success", "type": "output", "uuid": "chromatic_dimension", "timestamp": 1724163620692, "output_text": ""}
