{"result_id": "c62a45ec42154159bd34a0db7b1924cc", "data_type": null, "error": null, "metadata": {"namespace": "pipeline/resonant_kinesis", "path": "llm/rager/data_exporters/chromatic_dimension.py", "uuid": "1724164650301", "block_type": "data_exporter", "block_uuid": "chromatic_dimension", "execution_partition": null, "pipeline_uuid": "resonant_kinesis"}, "output": "", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "chromatic_dimension", "message": "from typing import Dict, List, Union\nimport numpy as np\nfrom elasticsearch import Elasticsearch, exceptions\nfrom datetime import datetime\nimport logging\nfrom elasticsearch.helpers import bulk\n\n# Configure logging\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(__name__)\n\n@data_exporter\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    logger.info(f\"Index name: {index_name}\")\n\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    try:\n        es_client = Elasticsearch(\n            connection_string,\n            timeout=30,  # Increase timeout as needed\n            max_retries=10,\n            retry_on_timeout=True,\n            sniff_on_start=True,  # Helps to auto-discover cluster nodes\n            sniff_on_connection_fail=True,  # Auto-discover nodes if a connection fails\n        )\n        logger.info(f'Connecting to Elasticsearch at {connection_string}')\n        \n        # List all indices\n        indices = es_client.cat.indices(format='json')\n        logger.info(\"Existing indices:\")\n        for index in indices:\n            logger.info(f\"Index name: {index['index']}\")\n            \n    except exceptions.ConnectionError as e:\n        logger.error(f\"Could not connect to Elasticsearch: {e}\")\n        return\n\n    # Define index settings with custom mappings\n    index_settings = {\n        \"settings\": {\n            \"number_of_shards\": number_of_shards,\n            \"number_of_replicas\": number_of_replicas\n        },\n        \"mappings\": {\n            \"properties\": {\n                \"text\": {\"type\": \"text\"},\n                \"section\": {\"type\": \"text\"},\n                \"question\": {\"type\": \"text\"},\n                \"course\": {\"type\": \"keyword\"},\n                \"document_id\": {\"type\": \"keyword\"},\n                vector_column_name: {\n                    \"type\": \"dense_vector\",\n                    \"dims\": dimensions\n                } if dimensions else {}\n            }\n        }\n    }\n\n    try:\n        if not es_client.indices.exists(index=index_name):\n            es_client.indices.create(index=index_name, body=index_settings)\n            logger.info(f'Index {index_name} created with settings: {index_settings}')\n            logger.info(f'Embedding dimensions: {dimensions}')\n        else:\n            logger.info(f\"Index {index_name} already exists.\")\n    except exceptions.RequestError as e:\n        logger.error(f\"Error creating index {index_name}: {e}\")\n        return\n\n    actions = [\n        {\n            \"_index\": index_name,\n            \"_source\": document\n        }\n        for document in documents\n    ]\n\n    try:\n        success, failed = bulk(es_client, actions)\n        logger.info(f\"Bulk indexing completed. Success: {success}, Failed: {failed}\")\n    except exceptions.BulkIndexError as e:\n        logger.error(f\"Error during bulk indexing: {e}\")\n    except exceptions.ConnectionError as e:\n        logger.error(f\"Connection error during indexing: {e}\")\n    except exceptions.RequestError as e:\n        logger.error(f\"Request error during indexing: {e}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n", "message_request_uuid": "1724164650301", "message_uuid": "f4bcfa04e3dd4d61a27d88fc39246f83", "output_manager": {"namespace": "pipeline/resonant_kinesis", "path": "llm/rager/data_exporters/chromatic_dimension.py", "uuid": "1724164650301"}, "pid": "f4bcfa04e3dd4d61a27d88fc39246f83", "pid_spawn": null, "source": "chromatic_dimension", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "chromatic_dimension"}, "status": "success", "type": "output", "uuid": "chromatic_dimension", "timestamp": 1724164654684, "output_text": ""}
