{"result_id": "77ccc6df3956433ca4c29479c2d9b578", "data_type": null, "error": {"code": "from typing import Dict, List, Union\nimport numpy as np\nfrom elasticsearch import Elasticsearch, exceptions\nfrom datetime import datetime\nimport logging\nfrom elasticsearch.helpers import bulk\n\n# Configure logging\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(__name__)\n\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    logger.info(f\"Index name: {index_name}\")\n\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    try:\n        es_client = Elasticsearch(\n            connection_string,\n            timeout=30,  # Increase timeout as needed\n            max_retries=10,\n            retry_on_timeout=True,\n            sniff_on_start=True,  # Helps to auto-discover cluster nodes\n            sniff_on_connection_fail=True,  # Auto-discover nodes if a connection fails\n        )\n        logger.info(f'Connecting to Elasticsearch at {connection_string}')\n    except exceptions.ConnectionError as e:\n        logger.error(f\"Could not connect to Elasticsearch: {e}\")\n        return\n\n    # Define index settings with custom mappings\n    index_settings = {\n        \"settings\": {\n            \"number_of_shards\": number_of_shards,\n            \"number_of_replicas\": number_of_replicas\n        },\n        \"mappings\": {\n            \"properties\": {\n                \"text\": {\"type\": \"text\"},\n                \"section\": {\"type\": \"text\"},\n                \"question\": {\"type\": \"text\"},\n                \"course\": {\"type\": \"keyword\"},\n                \"document_id\": {\"type\": \"keyword\"},\n                vector_column_name: {\n                    \"type\": \"dense_vector\",\n                    \"dims\": dimensions\n                } if dimensions else {}\n            }\n        }\n    }\n\n    try:\n        if not es_client.indices.exists(index=index_name):\n            es_client.indices.create(index=index_name, body=index_settings)\n            logger.info(f'Index {index_name} created with settings: {index_settings}')\n            logger.info(f'Embedding dimensions: {dimensions}')\n        else:\n            logger.info(f\"Index {index_name} already exists.\")\n    except exceptions.RequestError as e:\n        logger.error(f\"Error creating index {index_name}: {e}\")\n        return\n\n    actions = [\n        {\n            \"_index\": index_name,\n            \"_source\": document\n        }\n        for document in documents\n    ]\n\n    try:\n        success, failed = bulk(es_client, actions)\n        logger.info(f\"Bulk indexing completed. Success: {success}, Failed: {failed}\")\n    except exceptions.BulkIndexError as e:\n        logger.error(f\"Error during bulk indexing: {e}\")\n    except exceptions.ConnectionError as e:\n        logger.error(f\"Connection error during indexing: {e}\")\n    except exceptions.RequestError as e:\n        logger.error(f\"Request error during indexing: {e}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n", "code_context": [], "code_context_formatted": [], "error": "Block chromatic_dimension does not have any decorated functions. Make sure that a function in the block is decorated with @data_exporter.", "errors": null, "exception": "Exception: Block chromatic_dimension does not have any decorated functions. Make sure that a function in the block is decorated with @data_exporter.", "line_number": 1747, "message": "Block chromatic_dimension does not have any decorated functions. Make sure that a function in the block is decorated with @data_exporter.", "message_formatted": "Block chromatic_dimension does not have any decorated functions. Make sure that a function in the block is decorated with @data_exporter.", "stacktrace": ["Traceback (most recent call last):\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\", line 281, in execute_code_async\n    local_variables = await __modify_and_execute(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\", line 135, in __modify_and_execute\n    raise error\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\", line 117, in __modify_and_execute\n    res = await res\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/environments/setup_helpers.py\", line 48, in execute\n    await block.execute(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1711, in execute\n    await loop.run_in_executor(\n", "  File \"/usr/local/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1688, in execute_sync\n    return __execute()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1665, in __execute\n    raise err\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1567, in __execute\n    output = self.execute_block(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1912, in execute_block\n    outputs = self._execute_block(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 2063, in _execute_block\n    block_function = self._validate_execution(decorated_functions, input_vars)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1747, in _validate_execution\n    raise Exception(\n", "Exception: Block chromatic_dimension does not have any decorated functions. Make sure that a function in the block is decorated with @data_exporter.\n"], "stacktrace_formatted": ["\u001b[91mTraceback (most recent call last):\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\"\u001b[0m, \u001b[36mline 281\u001b[0m, \u001b[35min execute_code_async\n    local_variables = await __modify_and_execute(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\"\u001b[0m, \u001b[36mline 135\u001b[0m, \u001b[35min __modify_and_execute\n    raise error\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/execution.py\"\u001b[0m, \u001b[36mline 117\u001b[0m, \u001b[35min __modify_and_execute\n    res = await res\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/kernels/magic/environments/setup_helpers.py\"\u001b[0m, \u001b[36mline 48\u001b[0m, \u001b[35min execute\n    await block.execute(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1711\u001b[0m, \u001b[35min execute\n    await loop.run_in_executor(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/concurrent/futures/thread.py\"\u001b[0m, \u001b[36mline 58\u001b[0m, \u001b[35min run\n    result = self.fn(*self.args, **self.kwargs)\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1688\u001b[0m, \u001b[35min execute_sync\n    return __execute()\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1665\u001b[0m, \u001b[35min __execute\n    raise err\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1567\u001b[0m, \u001b[35min __execute\n    output = self.execute_block(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1912\u001b[0m, \u001b[35min execute_block\n    outputs = self._execute_block(\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 2063\u001b[0m, \u001b[35min _execute_block\n    block_function = self._validate_execution(decorated_functions, input_vars)\n\u001b[0m", "\u001b[34m  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\"\u001b[0m, \u001b[36mline 1747\u001b[0m, \u001b[35min _validate_execution\n    raise Exception(\n\u001b[0m", "\u001b[90mException: Block chromatic_dimension does not have any decorated functions. Make sure that a function in the block is decorated with @data_exporter.\n\u001b[0m", "\u001b[91mBlock chromatic_dimension does not have any decorated functions. Make sure that a function in the block is decorated with @data_exporter.\u001b[0m"], "type": "Exception"}, "metadata": null, "output": null, "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "chromatic_dimension", "message": "from typing import Dict, List, Union\nimport numpy as np\nfrom elasticsearch import Elasticsearch, exceptions\nfrom datetime import datetime\nimport logging\nfrom elasticsearch.helpers import bulk\n\n# Configure logging\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(__name__)\n\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    logger.info(f\"Index name: {index_name}\")\n\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    try:\n        es_client = Elasticsearch(\n            connection_string,\n            timeout=30,  # Increase timeout as needed\n            max_retries=10,\n            retry_on_timeout=True,\n            sniff_on_start=True,  # Helps to auto-discover cluster nodes\n            sniff_on_connection_fail=True,  # Auto-discover nodes if a connection fails\n        )\n        logger.info(f'Connecting to Elasticsearch at {connection_string}')\n    except exceptions.ConnectionError as e:\n        logger.error(f\"Could not connect to Elasticsearch: {e}\")\n        return\n\n    # Define index settings with custom mappings\n    index_settings = {\n        \"settings\": {\n            \"number_of_shards\": number_of_shards,\n            \"number_of_replicas\": number_of_replicas\n        },\n        \"mappings\": {\n            \"properties\": {\n                \"text\": {\"type\": \"text\"},\n                \"section\": {\"type\": \"text\"},\n                \"question\": {\"type\": \"text\"},\n                \"course\": {\"type\": \"keyword\"},\n                \"document_id\": {\"type\": \"keyword\"},\n                vector_column_name: {\n                    \"type\": \"dense_vector\",\n                    \"dims\": dimensions\n                } if dimensions else {}\n            }\n        }\n    }\n\n    try:\n        if not es_client.indices.exists(index=index_name):\n            es_client.indices.create(index=index_name, body=index_settings)\n            logger.info(f'Index {index_name} created with settings: {index_settings}')\n            logger.info(f'Embedding dimensions: {dimensions}')\n        else:\n            logger.info(f\"Index {index_name} already exists.\")\n    except exceptions.RequestError as e:\n        logger.error(f\"Error creating index {index_name}: {e}\")\n        return\n\n    actions = [\n        {\n            \"_index\": index_name,\n            \"_source\": document\n        }\n        for document in documents\n    ]\n\n    try:\n        success, failed = bulk(es_client, actions)\n        logger.info(f\"Bulk indexing completed. Success: {success}, Failed: {failed}\")\n    except exceptions.BulkIndexError as e:\n        logger.error(f\"Error during bulk indexing: {e}\")\n    except exceptions.ConnectionError as e:\n        logger.error(f\"Connection error during indexing: {e}\")\n    except exceptions.RequestError as e:\n        logger.error(f\"Request error during indexing: {e}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n", "message_request_uuid": "1724164418414", "message_uuid": "d0c0a76bed7041faaa6479a184ba5b79", "output_manager": {"namespace": "pipeline/resonant_kinesis", "path": "llm/rager/data_exporters/chromatic_dimension.py", "uuid": "1724164418414"}, "pid": "d0c0a76bed7041faaa6479a184ba5b79", "pid_spawn": null, "source": "chromatic_dimension", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "chromatic_dimension"}, "status": "error", "type": "status", "uuid": "chromatic_dimension", "timestamp": 1724164422711, "output_text": null}
{"result_id": "fded552a3db34c5a9626556073a8219d", "data_type": null, "error": null, "metadata": {"namespace": "pipeline/resonant_kinesis", "path": "llm/rager/data_exporters/chromatic_dimension.py", "uuid": "1724164418414", "block_type": "data_exporter", "block_uuid": "chromatic_dimension", "execution_partition": null, "pipeline_uuid": "resonant_kinesis"}, "output": "", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "chromatic_dimension", "message": "from typing import Dict, List, Union\nimport numpy as np\nfrom elasticsearch import Elasticsearch, exceptions\nfrom datetime import datetime\nimport logging\nfrom elasticsearch.helpers import bulk\n\n# Configure logging\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(__name__)\n\ndef elasticsearch(\n    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n):\n    \"\"\"\n    Exports document data to an Elasticsearch database.\n    \"\"\"\n\n    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n    index_name_prefix = kwargs.get('index_name', 'documents')\n    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n    index_name = f\"{index_name_prefix}_{current_time}\"\n    logger.info(f\"Index name: {index_name}\")\n\n    number_of_shards = kwargs.get('number_of_shards', 1)\n    number_of_replicas = kwargs.get('number_of_replicas', 0)\n    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n\n    dimensions = kwargs.get('dimensions')\n    if dimensions is None and len(documents) > 0:\n        document = documents[0]\n        dimensions = len(document.get(vector_column_name) or [])\n\n    try:\n        es_client = Elasticsearch(\n            connection_string,\n            timeout=30,  # Increase timeout as needed\n            max_retries=10,\n            retry_on_timeout=True,\n            sniff_on_start=True,  # Helps to auto-discover cluster nodes\n            sniff_on_connection_fail=True,  # Auto-discover nodes if a connection fails\n        )\n        logger.info(f'Connecting to Elasticsearch at {connection_string}')\n    except exceptions.ConnectionError as e:\n        logger.error(f\"Could not connect to Elasticsearch: {e}\")\n        return\n\n    # Define index settings with custom mappings\n    index_settings = {\n        \"settings\": {\n            \"number_of_shards\": number_of_shards,\n            \"number_of_replicas\": number_of_replicas\n        },\n        \"mappings\": {\n            \"properties\": {\n                \"text\": {\"type\": \"text\"},\n                \"section\": {\"type\": \"text\"},\n                \"question\": {\"type\": \"text\"},\n                \"course\": {\"type\": \"keyword\"},\n                \"document_id\": {\"type\": \"keyword\"},\n                vector_column_name: {\n                    \"type\": \"dense_vector\",\n                    \"dims\": dimensions\n                } if dimensions else {}\n            }\n        }\n    }\n\n    try:\n        if not es_client.indices.exists(index=index_name):\n            es_client.indices.create(index=index_name, body=index_settings)\n            logger.info(f'Index {index_name} created with settings: {index_settings}')\n            logger.info(f'Embedding dimensions: {dimensions}')\n        else:\n            logger.info(f\"Index {index_name} already exists.\")\n    except exceptions.RequestError as e:\n        logger.error(f\"Error creating index {index_name}: {e}\")\n        return\n\n    actions = [\n        {\n            \"_index\": index_name,\n            \"_source\": document\n        }\n        for document in documents\n    ]\n\n    try:\n        success, failed = bulk(es_client, actions)\n        logger.info(f\"Bulk indexing completed. Success: {success}, Failed: {failed}\")\n    except exceptions.BulkIndexError as e:\n        logger.error(f\"Error during bulk indexing: {e}\")\n    except exceptions.ConnectionError as e:\n        logger.error(f\"Connection error during indexing: {e}\")\n    except exceptions.RequestError as e:\n        logger.error(f\"Request error during indexing: {e}\")\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n", "message_request_uuid": "1724164418414", "message_uuid": "d0c0a76bed7041faaa6479a184ba5b79", "output_manager": {"namespace": "pipeline/resonant_kinesis", "path": "llm/rager/data_exporters/chromatic_dimension.py", "uuid": "1724164418414"}, "pid": "d0c0a76bed7041faaa6479a184ba5b79", "pid_spawn": null, "source": "chromatic_dimension", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "chromatic_dimension"}, "status": "success", "type": "output", "uuid": "chromatic_dimension", "timestamp": 1724164422723, "output_text": ""}
