{"result_id": "e21b18ee9be64a7daa82228d08ee6632", "data_type": "text/plain", "error": null, "metadata": null, "output": "91\n", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "auroral_omen", "message": "if 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\nimport re\nfrom typing import Any, Dict, List\n\nimport hashlib\n\ndef generate_document_id(doc):\n    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n    hash_object = hashlib.md5(combined.encode())\n    hash_hex = hash_object.hexdigest()\n    document_id = hash_hex[:8]\n    return document_id\n\n@transformer\ndef chunk_documents(data: List[Dict[str, Any]], *args, **kwargs):\n    documents = []\n\n    for doc in data['documents']:\n        doc['course'] = data['course']\n        # previously we used just \"id\" for document ID\n        doc['document_id'] = generate_document_id(doc)\n        documents.append(doc)\n\n    print(len(documents))\n    return documents", "message_request_uuid": "1724159981601", "message_uuid": "4e08289ca58b4872a7a690d227d3507b", "output_manager": {"namespace": "pipeline/resonant_kinesis", "path": "llm/rager/transformers/auroral_omen.py", "uuid": "1724159981601"}, "pid": "4e08289ca58b4872a7a690d227d3507b", "pid_spawn": null, "source": "auroral_omen", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "auroral_omen"}, "status": "running", "type": "stdout", "uuid": "auroral_omen", "timestamp": 1724159987764, "output_text": "91\n"}
{"result_id": "99cc9e92b8ee4f699d22e92d6694e08d", "data_type": null, "error": null, "metadata": {"namespace": "pipeline/resonant_kinesis", "path": "llm/rager/transformers/auroral_omen.py", "uuid": "1724159981601", "block_type": "transformer", "block_uuid": "auroral_omen", "execution_partition": null, "pipeline_uuid": "resonant_kinesis"}, "output": "", "process": {"data": [], "exitcode": null, "is_alive": false, "internal_state": "INIT", "kernel_uuid": "auroral_omen", "message": "if 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\nimport re\nfrom typing import Any, Dict, List\n\nimport hashlib\n\ndef generate_document_id(doc):\n    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n    hash_object = hashlib.md5(combined.encode())\n    hash_hex = hash_object.hexdigest()\n    document_id = hash_hex[:8]\n    return document_id\n\n@transformer\ndef chunk_documents(data: List[Dict[str, Any]], *args, **kwargs):\n    documents = []\n\n    for doc in data['documents']:\n        doc['course'] = data['course']\n        # previously we used just \"id\" for document ID\n        doc['document_id'] = generate_document_id(doc)\n        documents.append(doc)\n\n    print(len(documents))\n    return documents", "message_request_uuid": "1724159981601", "message_uuid": "4e08289ca58b4872a7a690d227d3507b", "output_manager": {"namespace": "pipeline/resonant_kinesis", "path": "llm/rager/transformers/auroral_omen.py", "uuid": "1724159981601"}, "pid": "4e08289ca58b4872a7a690d227d3507b", "pid_spawn": null, "source": "auroral_omen", "stream": "code_executions", "timestamp": null, "timestamp_end": null, "uuid": "auroral_omen"}, "status": "success", "type": "output", "uuid": "auroral_omen", "timestamp": 1724159987874, "output_text": ""}
