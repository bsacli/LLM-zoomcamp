{"text": "\u2705I got it working using `gcs-connector-hadoop-2.2.5-shaded.jar` and Spark 3.1\nI also added the google_credentials.json and .p12 to auth with gcs. These files are downloadable from GCP Service account.\nTo create the SparkSession:\nspark = SparkSession.builder.master('local[*]') \\\n.appName('spark-read-from-bigquery') \\\n.config('BigQueryProjectId','razor-project-xxxxxxx) \\\n.config('BigQueryDatasetLocation','de_final_data') \\\n.config('parentProject','razor-project-xxxxxxx) \\\n.config(\"google.cloud.auth.service.account.enable\", \"true\") \\\n.config(\"credentialsFile\", \"google_credentials.json\") \\\n.config(\"GcpJsonKeyFile\", \"google_credentials.json\") \\\n.config(\"spark.driver.memory\", \"4g\") \\\n.config(\"spark.executor.memory\", \"2g\") \\\n.config(\"spark.memory.offHeap.enabled\",True) \\\n.config(\"spark.memory.offHeap.size\",\"5g\") \\\n.config('google.cloud.auth.service.account.json.keyfile', \"google_credentials.json\") \\\n.config(\"fs.gs.project.id\", \"razor-project-xxxxxxx\") \\\n.config(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n.config(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\") \\\n.getOrCreate()", "section": "Module 5: pyspark", "question": "Spark fails when reading from BigQuery and using `.show()` on `SELECT` queries", "course": "data-engineering-zoomcamp", "document_id": "cabe8a5b"}