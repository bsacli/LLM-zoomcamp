{"text": "Got this error because the docker container memory was exhausted. The dta file was upto 800MB but my docker container does not have enough memory to handle that.\nSolution was to load the file in chunks with Pandas, then create multiple parquet files for each dat file I was processing. This worked smoothly and the issue was resolved.", "section": "Module 6: streaming with kafka", "question": "Negsignal:SIGKILL while converting dta files to parquet format", "course": "data-engineering-zoomcamp", "document_id": "676e1b76"}