{"text": "Problem:\nWhile passing local testing of the lambda function without issues, trying to test the same input with a running docker instance results in an error message like\n{\u2018errorMessage\u2019: \u2018Unable to marshal response: Object of type float32 is not JSON serializable\u2019, \u2018errorType\u2019: \u2018Runtime.MarshalError\u2019, \u2018requestId\u2019: \u2018f155492c-9af2-4d04-b5a4-639548b7c7ac\u2019, \u2018stackTrace\u2019: []}\nThis happens when a model (in this case the dino vs dragon model) returns individual estimation values as numpy float32 values (arrays). They need to be converted individually to base-Python floats in order to become \u201cserializable\u201d.\nSolution:\nIn my particular case, I set up the dino vs dragon model in such a way as to return a label + predicted probability for each class as follows (below is a two-line extract of function predict() in the lambda_function.py):\npreds = [interpreter.get_tensor(output_index)[0][0], \\\n1-interpreter.get_tensor(output_index)[0][0]]\nIn which case the above described solution will look like this:\npreds = [float(interpreter.get_tensor(output_index)[0][0]), \\\nfloat(1-interpreter.get_tensor(output_index)[0][0])]\nThe rest can be made work by following the chapter 9 (and/or chapter 5!) lecture videos step by step.\nAdded by Konrad Muehlberg", "section": "9. Serverless Deep Learning", "question": "Object of type float32 is not JSON serializable", "course": "machine-learning-zoomcamp", "document_id": "b2c0c554"}