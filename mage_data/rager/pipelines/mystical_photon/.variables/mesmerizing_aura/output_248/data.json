{"text": "Issue: If you don\u2019t define the column format while converting from csv to parquet Python will \u201cchoose\u201d based on the first rows.\n\u2705Solution: Defined the schema while running web_to_gcp.py pipeline.\nSebastian adapted the script:\nhttps://github.com/sebastian2296/data-engineering-zoomcamp/blob/main/week_4_analytics_engineering/web_to_gcs.py\nNeed a quick change to make the file work with gz files, added the following lines (and don\u2019t forget to delete the file at the end of each iteration of the loop to avoid any problem of disk space)\nfile_name_gz = f\"{service}_tripdata_{year}-{month}.csv.gz\"\nopen(file_name_gz, 'wb').write(r.content)\nos.system(f\"gzip -d {file_name_gz}\")\nos.system(f\"rm {file_name_init}.*\")\nSame ERROR - When running dbt run for fact_trips.sql, the task failed with error:\n\u201cParquet column 'ehail_fee' has type DOUBLE which does not match the target cpp_type INT64\u201d\n\u5f00\u542f\u5c4f\u5e55\u9605\u8bfb\u5668\u652f\u6301\n\u8981\u542f\u7528\u5c4f\u5e55\u9605\u8bfb\u5668\u652f\u6301\uff0c\u8bf7\u6309Ctrl+Alt+Z\u3002\u8981\u4e86\u89e3\u952e\u76d8\u5feb\u6377\u952e\uff0c\u8bf7\u6309Ctrl+\u659c\u6760\u3002\n\u67e5\u627e\u548c\u66ff\u6362\nReason: Parquet files have their own schema. Some parquet files for green data have records with decimals in ehail_fee column.\nThere are some possible fixes:\nDrop ehail_feel column since it is not really used. For instance when creating a partitioned table from the external table in BigQuery\nSELECT * EXCEPT (ehail_fee) FROM\u2026\nModify stg_green_tripdata.sql model using this line cast(0 as numeric) as ehail_fee.\nModify Airflow dag to make the conversion and avoid the error.\npv.read_csv(src_file, convert_options=pv.ConvertOptions(column_types = {'ehail_fee': 'float64'}))\nSame type of ERROR - parquet files with different data types - Fix it with pandas\nHere is another possibility that could be interesting:\nYou can specify the dtypes when importing the file from csv to a dataframe with pandas\npd.from_csv(..., dtype=type_dict)\nOne obstacle is that the regular int64 pandas use (I think this is from the numpy library) does not accept null values (NaN, not a number). But you can use the pandas Int64 instead, notice capital \u2018I\u2019. The type_dict is a python dictionary mapping the column names to the dtypes.\nSources:\nhttps://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\nNullable integer data type \u2014 pandas 1.5.3 documentation", "section": "Module 4: analytics engineering with dbt", "question": "DBT - I am having problems with columns datatype while running DBT/BigQuery", "course": "data-engineering-zoomcamp", "document_id": "8b14286c"}