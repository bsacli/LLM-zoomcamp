{"text": "Code executed:\ndf = spark.read.parquet(pq_path)\n\u2026 some operations on df \u2026\ndf.write.parquet(pq_path, mode=\"overwrite\")\njava.io.FileNotFoundException: File file:/home/xxx/code/data/pq/fhvhv/2021/02/part-00021-523f9ad5-14af-4332-9434-bdcb0831f2b7-c000.snappy.parquet does not exist\nThe problem is that Sparks performs lazy transformations, so the actual action that trigger the job is df.write, which does delete the parquet files that is trying to read (mode=\u201doverwrite\u201d)\n\u2705Solution: Write to a different directorydf\ndf.write.parquet(pq_path_temp, mode=\"overwrite\")", "section": "Module 5: pyspark", "question": "Error java.io.FileNotFoundException", "course": "data-engineering-zoomcamp", "document_id": "5fa98bd0"}