{"text": "If for whatever reason you try to read parquets directly from nyc.gov\u2019s cloudfront into pandas, you might run into this error:\npyarrow.lib.ArrowInvalid: Casting from timestamp[us] to timestamp[ns] would result in out of bounds\nCause:\nthere is one errant data record where the dropOff_datetime was set to year 3019 instead of 2019.\npandas uses \u201ctimestamp[ns]\u201d (as noted above), and int64 only allows a ~580 year range, centered on 2000. See `pd.Timestamp.max` and `pd.Timestamp.min`\nThis becomes out of bounds when pandas tries to read it because 3019 > 2300 (approx value of pd.Timestamp.Max\nFix:\nUse pyarrow to read it:\nimport pyarrow.parquet as pq df = pq.read_table('fhv_tripdata_2019-02.parquet').to_pandas(safe=False)\nHowever this results in weird timestamps for the offending record\nRead the datetime columns separately using pq.read_table\n\ntable = pq.read_table(\u2018taxi.parquet\u2019)\ndatetimes = [\u2018list of datetime column names\u2019]\ndf_dts = pd.DataFrame()\nfor col in datetimes:\ndf_dts[col] = pd.to_datetime(table .column(col), errors='coerce')\n\nThe `errors=\u2019coerce\u2019` parameter will convert the out of bounds timestamps into either the max or the min\nUse parquet.compute.filter to remove the offending rows\n\nimport pyarrow.compute as pc\ntable = pq.read_table(\"\u2018taxi.parquet\")\ndf = table.filter(\npc.less_equal(table[\"dropOff_datetime\"], pa.scalar(pd.Timestamp.max))\n).to_pandas()", "section": "error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.", "question": "Homework - Reading parquets from nyc.gov directly into pandas returns Out of bounds error", "course": "data-engineering-zoomcamp", "document_id": "a4ba2478"}