{"text": "After installing all including pyspark (and it is successfully imported), but then running this script on the jupyter notebook\nimport pyspark\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n.master(\"local[*]\") \\\n.appName('test') \\\n.getOrCreate()\ndf = spark.read \\\n.option(\"header\", \"true\") \\\n.csv('taxi+_zone_lookup.csv')\ndf.show()\nit gives the error:\nRuntimeError: Java gateway process exited before sending its port number\n\u2705The solution (for me) was:\npip install findspark on the command line and then\nAdd\nimport findspark\nfindspark.init()\nto the top of the script.\nAnother possible solution is:\nCheck that pyspark is pointing to the correct location.\nRun pyspark.__file__. It should be list /home/<your user name>/spark/spark-3.0.3-bin-hadoop3.2/python/pyspark/__init__.py if you followed the videos.\nIf it is pointing to your python site-packages remove the pyspark directory there and check that you have added the correct exports to you .bashrc file and that there are not any other exports which might supersede the ones provided in the course content.\nTo add to the solution above, if the errors persist in regards to setting the correct path for spark,  an alternative solution for permanent path setting solve the error is  to set environment variables on system and user environment variables following this tutorial: Install Apache PySpark on Windows PC | Apache Spark Installation Guide\nOnce everything is installed, skip to 7:14 to set up environment variables. This allows for the environment variables to be set permanently.", "section": "Module 5: pyspark", "question": "lsRuntimeError: Java gateway process exited before sending its port number", "course": "data-engineering-zoomcamp", "document_id": "3b5b4eb3"}