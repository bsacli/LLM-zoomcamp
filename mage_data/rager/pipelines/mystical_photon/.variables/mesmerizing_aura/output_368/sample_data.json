{"text": "Ans: No, you can submit a job to DataProc from your local computer by installing gsutil (https://cloud.google.com/storage/docs/gsutil_install) and configuring it. Then, you can execute the following command from your local computer.\ngcloud dataproc jobs submit pyspark \\\n--cluster=de-zoomcamp-cluster \\\n--region=europe-west6 \\\ngs://dtc_data_lake_de-zoomcamp-nytaxi/code/06_spark_sql.py \\\n-- \\\n--input_green=gs://dtc_data_lake_de-zoomcamp-nytaxi/pq/green/2020/*/ \\\n--input_yellow=gs://dtc_data_lake_de-zoomcamp-nytaxi/pq/yellow/2020/*/ \\\n--output=gs://dtc_data_lake_de-zoomcamp-nytaxi/report-2020 (edited)", "section": "Module 5: pyspark", "question": "Dataproc Qn: Is it essential to have a VM on GCP for running Dataproc and submitting jobs ?", "course": "data-engineering-zoomcamp", "document_id": "591df4e6"}