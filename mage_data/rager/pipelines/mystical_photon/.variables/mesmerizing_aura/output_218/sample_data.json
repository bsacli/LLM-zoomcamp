{"text": "There are multiple benefits of using Cloud Functions to automate tasks in Google Cloud.\nUse below Cloud Function python script to load files directly to BigQuery. Use your project id, dataset id & table id as defined by you.\nimport tempfile\nimport requests\nimport logging\nfrom google.cloud import bigquery\ndef hello_world(request):\n# table_id = <project_id.dataset_id.table_id>\ntable_id = 'de-zoomcap-project.dezoomcamp.fhv-2019'\n# Create a new BigQuery client\nclient = bigquery.Client()\nfor month in range(4, 13):\n# Define the schema for the data in the CSV.gz files\nurl = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-{:02d}.csv.gz'.format(month)\n# Download the CSV.gz file from Github\nresponse = requests.get(url)\n# Create new table if loading first month data else append\nwrite_disposition_string = \"WRITE_APPEND\" if month > 1 else \"WRITE_TRUNCATE\"\n# Defining LoadJobConfig with schema of table to prevent it from changing with every table\njob_config = bigquery.LoadJobConfig(\nschema=[\nbigquery.SchemaField(\"dispatching_base_num\", \"STRING\"),\nbigquery.SchemaField(\"pickup_datetime\", \"TIMESTAMP\"),\nbigquery.SchemaField(\"dropOff_datetime\", \"TIMESTAMP\"),\nbigquery.SchemaField(\"PUlocationID\", \"STRING\"),\nbigquery.SchemaField(\"DOlocationID\", \"STRING\"),\nbigquery.SchemaField(\"SR_Flag\", \"STRING\"),\nbigquery.SchemaField(\"Affiliated_base_number\", \"STRING\"),\n],\nskip_leading_rows=1,\nwrite_disposition=write_disposition_string,\nautodetect=True,\nsource_format=\"CSV\",\n)\n# Load the data into BigQuery\n# Create a temporary file to prevent the exception- AttributeError: 'bytes' object has no attribute 'tell'\"\nwith tempfile.NamedTemporaryFile() as f:\nf.write(response.content)\nf.seek(0)\njob = client.load_table_from_file(\nf,\ntable_id,\nlocation=\"US\",\njob_config=job_config,\n)\njob.result()\nlogging.info(\"Data for month %d successfully loaded into table %s.\", month, table_id)\nreturn 'Data loaded into table {}.'.format(table_id)", "section": "Module 3: Data Warehousing", "question": "GCP BQ - Tip: Using Cloud Function to read csv.gz files from github directly to BigQuery in Google Cloud:", "course": "data-engineering-zoomcamp", "document_id": "c489266b"}