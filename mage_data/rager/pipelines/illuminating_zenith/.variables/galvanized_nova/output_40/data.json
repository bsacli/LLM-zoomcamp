{"text": "To solve this you need to pull one of these models first: https://ollama.com/library . Also check the proper name of the module.\nAdded by Taras Goriachko\nOllama: Running Ollama locally on Colab gives error after the llm() line\nAPIConnectionError: Connection error.\nIt seems to be running at localhost:11434 however localhost:11434/v1/ gives 404\nFound a solution in the Medium article and this link:\nhttps://medium.com/@mauryaanoop3/running-ollama-on-google-colab-free-tier-a-step-by-step-guide-9ef74b1f8f7a\nhttps://github.com/ollama/ollama/issues/703\nAdded by Hanaa", "section": "Module 2: Open-Source LLMs", "question": "Ollama: Error: NotFoundError: Error code: 404 - {'error': {'message': \"model XXX not found, try pulling it first\" \u2026", "course": "llm-faq-v1", "document_id": "d75d67bc"}